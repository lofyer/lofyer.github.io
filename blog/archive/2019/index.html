<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content=lofyer><link href=https://docs.lofyer.org/blog/archive/2019/ rel=canonical><link href=../2020/ rel=prev><link href=../2018/ rel=next><link rel=icon href=../../../images/favicon.ico><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.39"><title>2019 - Lofyer's Blog</title><link rel=stylesheet href=../../../assets/stylesheets/main.8c3ca2c6.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#2019 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../../.. title="Lofyer's Blog" class="md-header__button md-logo" aria-label="Lofyer's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Lofyer's Blog </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 2019 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=查找> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/lofyer/lofyer.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> lofyer/lofyer.github.io </div> </a> </div> </nav> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Index </a> </li> <li class=md-tabs__item> <a href=../../../wangsheng/ class=md-tabs__link> WangSheng </a> </li> <li class=md-tabs__item> <a href=../../../datanote/ class=md-tabs__link> Archive Docs </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Archive Blog </a> </li> <li class=md-tabs__item> <a href=../../../tags/ class=md-tabs__link> Tags </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Lofyer's Blog" class="md-nav__button md-logo" aria-label="Lofyer's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Lofyer's Blog </label> <div class=md-nav__source> <a href=https://github.com/lofyer/lofyer.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> lofyer/lofyer.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Index </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../wangsheng/ class=md-nav__link> <span class=md-ellipsis> WangSheng </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../datanote/ class=md-nav__link> <span class=md-ellipsis> Archive Docs </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Archive Blog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Archive Blog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../ class=md-nav__link> <span class=md-ellipsis> 首页 </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2 checked> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> 归档 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=true> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> 归档 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../2022/ class=md-nav__link> <span class=md-ellipsis> 2022 </span> </a> </li> <li class=md-nav__item> <a href=../2021/ class=md-nav__link> <span class=md-ellipsis> 2021 </span> </a> </li> <li class=md-nav__item> <a href=../2020/ class=md-nav__link> <span class=md-ellipsis> 2020 </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 2019 </span> </a> </li> <li class=md-nav__item> <a href=../2018/ class=md-nav__link> <span class=md-ellipsis> 2018 </span> </a> </li> <li class=md-nav__item> <a href=../2017/ class=md-nav__link> <span class=md-ellipsis> 2017 </span> </a> </li> <li class=md-nav__item> <a href=../2016/ class=md-nav__link> <span class=md-ellipsis> 2016 </span> </a> </li> <li class=md-nav__item> <a href=../2015/ class=md-nav__link> <span class=md-ellipsis> 2015 </span> </a> </li> <li class=md-nav__item> <a href=../2014/ class=md-nav__link> <span class=md-ellipsis> 2014 </span> </a> </li> <li class=md-nav__item> <a href=../2013/ class=md-nav__link> <span class=md-ellipsis> 2013 </span> </a> </li> <li class=md-nav__item> <a href=../2012/ class=md-nav__link> <span class=md-ellipsis> 2012 </span> </a> </li> <li class=md-nav__item> <a href=../2011/ class=md-nav__link> <span class=md-ellipsis> 2011 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../category/lab/ class=md-nav__link> <span class=md-ellipsis> 分类 </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <div class=md-content__inner> <header class=md-typeset> <h1 id=2019>2019</h1> </header> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2019-11-17 00:00:00">2019年11月17日</time></li> <li class=md-meta__item> 分类于 <a href=../../category/cloud-infra/ class=md-meta__link>cloud-infra</a></li> <li class=md-meta__item> 需要 1 分钟阅读时间 </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=armx86><a href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/ class=toclink>ARM/X86服务器的安卓市场（虚拟化、容器）</a></h2> <h2 id=0><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#0>0. 背景</a></h2> <p>随着国产化进程的推进，相当的应用已经可在国产化服务器（ARM/X86）上运行，本文将使用容器以及虚拟化两种技术对ARM/X86服务器上运行高性能的Android桌面进行探索。</p> <p>调研了一圈实现，业界性价比最高的还是用板卡。。但是初始研究成本高一些，决心做的话可以先买一些现成的深圳货，但是对于入门的厂商来说还是用arm服务器跑容器合适，毕竟是安卓。</p> <h2 id=1-armx86><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#1-armx86>1. ARM/X86服务器</a></h2> <h3 id=11><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#11>1.1. 虚拟化</a></h3> <p>使用X86服务器去虚拟化Android的厂商确实不多，社区有提供X86版本Android模，使用X86去模拟ARM版本的Android几乎没人做（效率极差）。</p> <p>但是随着国内这几年ARM服务器市场上来，不少厂商早就开始探索ARM服务器去虚拟ARM版Android了，虽然效率较X86有很大提升，但是相比容器技术代价仍然很高，模拟出的手机定价低导致大家都是探索性的尝试。</p> <h3 id=12><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#12>1.2. 容器</a></h3> <p>这已经是一个较为成熟的技术了，但是缺点在于虚拟出的设备不完善。</p> <p>Docker-Android</p> <p>Anbox(LXC)</p> <p>Xdroid</p> <h3 id=2-gpu><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#2-gpu>2. GPU</a></h3> <h4 id=nvidia><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#nvidia>NVIDIA</a></h4> <h4 id=mali><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#mali>Mali</a></h4> <h2 id=3><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#3>3. 桌面协议</a></h2> <p>凡上上规模的Android模拟都需要成熟的桌面协议，而这又与他采用GPU设备相关。</p> <p>由于qemu的ARM模拟的VGA设备由于其天生架构问题，不能正常使用，因而暂时需要使用virtio-vga设备方可显示（https://www.linux-kvm.org//blog/images/0/09/Qemu-gfx-2016.pdf）。</p> <h3 id=31><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#31>3.1. 带内协议</a></h3> <p>VNC</p> <p>SPICE</p> <p>RDP/ICA</p> <p>PCoIP</p> <h3 id=32><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#32>3.2. 带外协议</a></h3> <p>VNC</p> <p>SPICE</p> <p>PCoIP--- title: "Building the infrastructure for cloud security" date: 2015-02-08 categories: - "cloud-infra"</p> <hr> <p><strong>Host</strong> TPM Attesation Mt. Wilson Geo-tag HyTrust McAfee ePO</p> <p><strong>VM management</strong> SSO SDN VLAN Firewall</p> <h3 id=vm-appliance-mystery-hill><a class=toclink href=../../2019/11/17/armx86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E5%8D%93%E5%B8%82%E5%9C%BA%E8%99%9A%E6%8B%9F%E5%8C%96%E5%AE%B9%E5%99%A8/#vm-appliance-mystery-hill><strong>VM Appliance</strong> Mystery Hill</a></h3> <p>title: "Home-based hybridcloud（家庭作坊式混合云）" date: 2017-10-24 categories: - "cloud-infra" - "linux-admin"</p> <hr> <p>名字起的不好听，不过无所谓，也是混合云了，做到了什么地步呢？ 在数据层面，家中机器和linode以及gcp公有云全通，任意地点的客户端可以通过局域网地址访问家中和公有云，而这一且，只需要一个公网IP。那么如何组建呢？</p> <ol> <li> <p><strong>选择一个趁手的VPN</strong>，这里我使用的是SoftEther，全平台全功能，图形界面客户端全都有，自带域名反向解析，自带公网，又那么稳定，为啥不用。 只要在家中的一台PC上装好服务端，把5555端口通过路由器（有公网IP）映射出去即可完成VPN服务器的搭建。</p> </li> <li> <p><strong>Linode服务器集群选择一台作为网关（边界路由器）</strong>，负责作为客户端接入VPN服务器，那么它就有了192.168.0段的地址，其它机器上因为linode没有VPC的概念，所以得加条到192.168.0.0/24的路由。</p> </li> <li> <p>总结下来，接入到home的VPN服务器会给所有客户端一个home的IP地址，然后加的路由表（使linode集群的10段暴露出去）都围绕这个地址展开达到互通的目的。</p> </li> <li> <p>目前我把linode上分散在全球8个机房的私有服务器都加了进来，当然，安全线路。尝试了一次kcptun加速VPN连接，但是linux下失败了，windows成功。</p> </li> </ol> <p>这是图，PC-Server为VPN服务器，LINODE为公有云，也加入了Google的公有云进去（没画），Windows-PC为个人服务器。</p> <p><a href=https://blog.lofyer.org/wp-content/uploads/homebasedhybridcloud-1.png><img alt src=/blog/images/homebasedhybridcloud-1.png></a></p> <p>联通之后，Google的CDN、DNS可以混合到Linode去使用了，再展开点，大数据、数据库都可以结合Linode去跑了。</p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2019-09-22 00:00:00">2019年9月22日</time></li> <li class=md-meta__item> 分类于 <a href=../../category/abm/ class=md-meta__link>abm</a>, <a href=../../category/ai/ class=md-meta__link>ai</a></li> <li class=md-meta__item> 需要 5 分钟阅读时间 </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=agent-based-modeling><a href=../../2019/09/22/tensorflow-in-netlogo-make-your-agent-more-intelligent/ class=toclink>Agent based modeling相关</a></h2> <hr> <h3 id=tensorflow-in-netlogo-make-your-agent-more-intelligent><a class=toclink href=../../2019/09/22/tensorflow-in-netlogo-make-your-agent-more-intelligent/#tensorflow-in-netlogo-make-your-agent-more-intelligent>TensorFlow in NetLogo, Make Your Agent More Intelligent</a></h3> <h4 id=0-background><a class=toclink href=../../2019/09/22/tensorflow-in-netlogo-make-your-agent-more-intelligent/#0-background>0. Background</a></h4> <p>NetLogo is a very useful tools for ABM, and Python is also a handful language for building proof of concept.</p> <p>In this post I will show you how to call python language in NetLogo. For more information please <a href=https://github.com/NetLogo/Python-Extension>follow here</a>.</p> <h4 id=1-netlogo-version><a class=toclink href=../../2019/09/22/tensorflow-in-netlogo-make-your-agent-more-intelligent/#1-netlogo-version>1. NetLogo version</a></h4> <p><a href=https://blog.lofyer.org/wp-content/uploads/WX20190922-211123@2x.png><img alt src=/blog/images/WX20190922-211123@2x-1024x958.png></a></p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span>
<span class=normal>44</span>
<span class=normal>45</span>
<span class=normal>46</span>
<span class=normal>47</span>
<span class=normal>48</span>
<span class=normal>49</span>
<span class=normal>50</span>
<span class=normal>51</span>
<span class=normal>52</span>
<span class=normal>53</span>
<span class=normal>54</span>
<span class=normal>55</span>
<span class=normal>56</span>
<span class=normal>57</span>
<span class=normal>58</span>
<span class=normal>59</span>
<span class=normal>60</span>
<span class=normal>61</span>
<span class=normal>62</span>
<span class=normal>63</span>
<span class=normal>64</span>
<span class=normal>65</span>
<span class=normal>66</span>
<span class=normal>67</span>
<span class=normal>68</span>
<span class=normal>69</span>
<span class=normal>70</span>
<span class=normal>71</span>
<span class=normal>72</span>
<span class=normal>73</span>
<span class=normal>74</span>
<span class=normal>75</span>
<span class=normal>76</span>
<span class=normal>77</span>
<span class=normal>78</span>
<span class=normal>79</span>
<span class=normal>80</span>
<span class=normal>81</span>
<span class=normal>82</span>
<span class=normal>83</span></pre></div></td><td class=code><div><pre><span></span><code>breed [data-points data-point]
breed [centroids centroid]

globals [
  any-centroids-moved?
]

to setup
  clear-all
  set-default-shape data-points &quot;circle&quot;
  set-default-shape centroids &quot;x&quot;
  generate-clusters
  reset-centroids
end

to generate-clusters
  let cluster-std-dev 20 - num-clusters
  let cluster-size num-data-points / num-clusters
  repeat num-clusters [
    let center-x random-xcor / 1.5
    let center-y random-ycor / 1.5
    create-data-points cluster-size [
      setxy center-x center-y
      set heading random 360
      fd abs random-normal 0 (cluster-std-dev / 2) ;; Divide by two because abs doubles the width
    ]
  ]
end

to reset-centroids
  set any-centroids-moved? true
  ask data-points [ set color grey ]

  let colors base-colors
  ask centroids [die]
  create-centroids num-centroids [
    move-to one-of data-points
    set size 5
    set color last colors + 1
    set colors butlast colors
  ]
  clear-all-plots
  reset-ticks
end

to go
  if not any-centroids-moved? [stop]
  set any-centroids-moved? false
  assign-clusters
  update-clusters
  tick
end

to assign-clusters
  ask data-points [set color [color] of closest-centroid - 2]
end

to update-clusters
  let movement-threshold 0.1
  ask centroids [
    let my-points data-points with [ shade-of? color [ color ] of myself ]
    if any? my-points [
      let new-xcor mean [ xcor ] of my-points
      let new-ycor mean [ ycor ] of my-points
      if distancexy new-xcor new-ycor &gt; movement-threshold [
        set any-centroids-moved? true
      ]
      setxy new-xcor new-ycor
    ]
  ]
  update-plots
end

to-report closest-centroid
  report min-one-of centroids [ distance myself ]
end

to-report square-deviation
  report sum [ (distance myself) ^ 2 ] of data-points with [ closest-centroid = myself ]
end

; Copyright 2014 Uri Wilensky.
; See Info tab for full copyright and license.
</code></pre></div></td></tr></table></div> <h4 id=2-tensorflow-version><a class=toclink href=../../2019/09/22/tensorflow-in-netlogo-make-your-agent-more-intelligent/#2-tensorflow-version>2. TensorFlow version</a></h4> <p>TensorFlow version: 1.14</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span></pre></div></td><td class=code><div><pre><span></span><code>import numpy as np
import tensorflow as tf

num-points = 100
dimensions = 2
points = np.random.uniform(0, 1000, [num-points, dimensions])

def input-fn():
  return tf.compat.v1.train.limit-epochs(
      tf.convert-to-tensor(points, dtype=tf.float32), num-epochs=1)

num-clusters = 5
kmeans = tf.contrib.factorization.KMeansClustering(
    num-clusters=num-clusters, use-mini-batch=False)

# train
num-iterations = 10
previous-centers = None
for - in xrange(num-iterations):
  kmeans.train(input-fn)
  cluster-centers = kmeans.cluster-centers()
  if previous-centers is not None:
    print &#39;delta:&#39;, cluster-centers - previous-centers
  previous-centers = cluster-centers
  print &#39;score:&#39;, kmeans.score(input-fn)
print &#39;cluster centers:&#39;, cluster-centers

# map the input points to their clusters
cluster-indices = list(kmeans.predict-cluster-index(input-fn))
for i, point in enumerate(points):
  cluster-index = cluster-indices[i]
  center = cluster-centers[cluster-index]
  print &#39;point:&#39;, point, &#39;is in cluster&#39;, cluster-index, &#39;centered at&#39;, center
</code></pre></div></td></tr></table></div> <h4 id=3-netlogo-with-python-extension-version><a class=toclink href=../../2019/09/22/tensorflow-in-netlogo-make-your-agent-more-intelligent/#3-netlogo-with-python-extension-version>3. NetLogo with Python Extension version</a></h4> <p>Here's the snapshot.</p> <p><a href=https://blog.lofyer.org/wp-content/uploads/WX20191028-204937@2x.png><img alt src=/blog/images/WX20191028-204937@2x.png></a></p> <p>And here's the code.</p> <p>extensions [ py ]</p> <p>breed [data-points data-point] breed [centroids centroid]</p> <p>data-points-own [ cluster-id ]</p> <p>centroids-own [ cluster-id centx centy ]</p> <p>globals [ testoutput centroid-list ]</p> <p>to setup clear-all py:setup py:python (py:run "import tensorflow as tf" "import numpy as np" ) set testoutput py:runresult "1" py:set "testoutput" testoutput set-default-shape data-points "circle" set-default-shape centroids "x" generate-clusters ; For python py:set "num-points" num-clusters py:set "points" [list xcor ycor] of data-points py:set "num-clusters" num-clusters py:set "num-round" num-round if debug = True [ py:run "print('Points Cordinates:', points)" ;for debug ] ;reset-centroids end</p> <p>to generate-clusters set testoutput py:runresult "testoutput + 1" let cluster-std-dev cluster-range let cluster-size num-data-points / num-clusters repeat num-clusters [ let center-x random-xcor / 1.5 let center-y random-ycor / 1.5 create-data-points cluster-size [ setxy center-x center-y set heading random 360 fd abs random-normal 0 (cluster-std-dev / 2) ] ] end</p> <p>to train ; Cluster center (py:run "points = np.asarray(points)" "def input-fn():" " return tf.compat.v1.train.limit-epochs(tf.convert-to-tensor(points, dtype=tf.float32), num-epochs=1)" "kmeans = tf.contrib.factorization.KMeansClustering(num-clusters=num-clusters, use-mini-batch=False)" "num-iterations = num-round" "previous-centers = None" "for - in range(num-iterations):" " kmeans.train(input-fn)" " cluster-centers = kmeans.cluster-centers()" " if previous-centers is not None:" " print(('delta:', cluster-centers - previous-centers))" " previous-centers = cluster-centers" " print(('score:', kmeans.score(input-fn)))" "print(('cluster centers:', cluster-centers))" "# map the input points to their clusters" "cluster-indices = list(kmeans.predict-cluster-index(input-fn))" "print('cluster indices: ', cluster-indices)" "for i, point in enumerate(points):" " cluster-index = cluster-indices[i]" " center = cluster-centers[cluster-index]" " print(('point:', point, 'is in cluster', cluster-index, 'centered at', center))" ) end</p> <p>to show-shape set centroid-list py:runresult "cluster-centers" foreach centroid-list [ x -&gt; create-centroids 1 [ set xcor ( item 0 x ) set ycor ( item 1 x ) set size 3 set color white ] ] end</p> <p>Ref:</p> <p>[1] <a href=https://www.altoros.com/blog/using-k-means-clustering-in-tensorflow/ >https://www.altoros.com/blog/using-k-means-clustering-in-tensorflow/</a></p> <p>[2] <a href=https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeansClustering>https://www.tensorflow.org/api-docs/python/tf/contrib/factorization/KMeansClustering</a></p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2019-05-23 00:00:00">2019年5月23日</time></li> <li class=md-meta__item> 分类于 <a href=../../category/filecoin/ class=md-meta__link>filecoin</a></li> <li class=md-meta__item> 需要 2 分钟阅读时间 </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=filecoin><a href=../../2019/05/23/lotus-howto/ class=toclink>Filecoin 搭建</a></h2> <p>本文旨在避坑，本人作为矿工时期会保持更新。</p> <h3 id=1><a class=toclink href=../../2019/05/23/lotus-howto/#1>1. 硬件与存储配置</a></h3> <p>需要的机器整体分为三种，包括主节点lotus（同步主网）、矿工节点miner（）</p> <p><strong>管理节点(node200)</strong></p> <ul> <li> <p>CPU Intel 4110R x 2</p> </li> <li> <p>内存128G</p> </li> <li> <p>无限卡</p> </li> <li> <p>128G系统盘（M.2）</p> </li> </ul> <p><strong>主节点与矿工节点(node201)</strong></p> <ul> <li> <p>CPU Intel 4110R x 2</p> </li> <li> <p>内存256G</p> </li> <li> <p>无显卡</p> </li> </ul> <p><strong>工作节点1(node202)</strong></p> <ul> <li> <p>CPU Intel 4110 x 2</p> </li> <li> <p>内存372G</p> </li> </ul> <p><strong>工作节点2(node203)</strong></p> <ul> <li> <p>CPU AMD 7302 x 2</p> </li> <li> <p>Driver: NVIDIA-Linux-x86_64-460.91.03.run</p> </li> </ul> <h3 id=2><a class=toclink href=../../2019/05/23/lotus-howto/#2>2. 编译</a></h3> <p>我们需要根据不同的CPU型号来编译不同的二进制文件，源码文件建议放在共享目录中，如果机器数量足够多二进制文件也需要单独存放减少编译负担。</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span></pre></div></td><td class=code><div><pre><span></span><code>#!/bin/bash
set -x
VERSION=v1.11.1
source /root/env-lotus
source /root/env-proxy
#curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh
#wget -c https://golang.org/dl/go1.16.7.linux-amd64.tar.gz -O - | sudo tar -xz -C /usr/local
#echo &quot;export PATH=$PATH:/usr/local/go/bin&quot; &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc

cd /filecoin/cache/build/lotus
make clean
git checkout master
git pull
git checkout $VERSION
git submodule deinit --all
git submodule update --init
# Some older Intel and AMD processors WITHOUT the ADX instruction support may panic with illegal instruction errors.
LSCPU=$(lscpu|grep -i adx)
if [[ $? == 0 ]]
then
    echo &quot;Instruction ADX detected.&quot;
else
    export CGO_CFLAGS_ALLOW=&quot;-D__BLST_PORTABLE__&quot;
    export CGO_CFLAGS=&quot;-D__BLST_PORTABLE__&quot;
fi
# If you have an AMD Zen or Intel Ice Lake CPU (or later), ENABLE the use of SHA extensions by adding these two environment variables:
LSCPU=$(lscpu|grep -i &#39; sha&#39;)
if [[ $? == 0 ]]
then
    echo &quot;Instruction SHA detected.&quot;
    export RUSTFLAGS=&quot;-C target-cpu=native -g&quot;
    export FFI_BUILD_FROM_SOURCE=1
fi
make -j16
make lotus-bench
make install
export https_proxy=
</code></pre></div></td></tr></table></div> <h3 id=3><a class=toclink href=../../2019/05/23/lotus-howto/#3>3. 分角色配置</a></h3> <p><strong>主节点与矿工节点(node201)</strong></p> <p>这里我们的主节点与矿工节点使用同一台主机，其环境变量配置如下。</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span></pre></div></td><td class=code><div><pre><span></span><code>#!/bin/bash
export BELLMAN_CPU_UTILIZATION=0.875
export FIL_PROOFS_MAXIMIZE_CACHING=1
export FIL_PROOFS_USE_GPU_COLUMN_BUILDER=0
export FIL_PROOFS_USE_GPU_TREE_BUILDER=0
export FIL_PROOFS_USE_MULTICORE_SDR=1
export FIL_PROOFS_SDR_PARENTS_CACHE_SIZE=1073741824
#export RUST_BACKTRACE=full
#export RUST_LOG=debug

export FULLNODE_API_INFO=&quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBbGxvdyI6WyJyZWFkIiwid3JpdGUiLCJzaWduIiwiYWRtaW4iXX0.Wq0nVk1xEpwsrQhfxpk2Vb5lBS07NeJ6o4ZJRGoQuic:/ip4/192.168.0.101/tcp/1234/http&quot;
export MINER_API_INFO=&quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBbGxvdyI6WyJyZWFkIiwid3JpdGUiLCJzaWduIiwiYWRtaW4iXX0.c6SQus7UjC4rh-OKhi45f3RGr9UyH8jURrDsA521ZQ8:/ip4/192.168.0.101/tcp/2345/http&quot;

export LOTUS_PATH=/filecoin/data/node/ # When using a local node.
export LOTUS_MINER_PATH=/filecoin/data/miner/
export LOTUS_WORKER_PATH=/filecoin/data/worker/

export FIL_PROOFS_PARAMETER_CACHE=/filecoin/cache/parameter/
export FIL_PROOFS_PARENT_CACHE=/filecoin/cache/parent/
export TMPDIR=/filecoin/cache/tmp/


export IPFS_GATEWAY=https://proof-parameters.s3.cn-south-1.jdcloud-oss.com/ipfs/
export GOPROXY=https://goproxy.cn
</code></pre></div></td></tr></table></div> <h3 id=3_1><a class=toclink href=../../2019/05/23/lotus-howto/#3_1>3. 测试</a></h3> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>编译完成后，需要对机器的能力进行简单测试，防止某些配置情况导致
</code></pre></div></td></tr></table></div> <h3 id=3_2><a class=toclink href=../../2019/05/23/lotus-howto/#3_2>3. 过程控制</a></h3> <p>虽然lotus的调度过程非常的傻，网上也有不少的文章都说对lotus的封装调度进行了优化，但是它一般是建立在机器数量较多的前提下，对于数量较少单个机器同时承载多个角色的情况，我们可以观察每个扇区在不同过程的表现来进行适当控制。</p> <p>每个扇区在不同过程的消耗可以参考<a href=https://docs.filecoin.io/mine/lotus/seal-workers/#resource-allocation-in-lotus-workers>Task resource table</a>。封装整体分为PreCommit与Commit两个过程，每个过程中又有两个不同阶段。其中，P1扇区可以并发，P2可以并发但会独占某个GPU，C1过程很快且可以并发，C2过程独占某个GPU且会排斥除AP外的其他任何新增阶段。</p> <p>以扇区作为sectorsAgent，机器作为workerAgent，那么我们先定义sectorAgent的行为（为方便计算，假设每个扇区封装过程中占用空间为500G，不同的lotus版本、机器配置扇区封装过程表现的现象可能不同）。</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span></pre></div></td><td class=code><div><pre><span></span><code>sectorAgent:
AP -&gt; P1(6h, 60G MEM) -&gt; P2(2h, 20G MEM, GPU, Parallel) -&gt; PreCommitAggregate -&gt; C1(0.5h, 1G MEM) -&gt; C2(1-2h, 200G MEM, only Parallel with GPU) -&gt; SubmitCommitAggregate -&gt; Submit

workerAgent:
Worker1(CPU only, 376G MEM)
Worker2(wtih GPU, 1T MEM)
</code></pre></div></td></tr></table></div> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2019-05-10 00:00:00">2019年5月10日</time></li> <li class=md-meta__item> 分类于 <a href=../../category/cloud-infra/ class=md-meta__link>cloud-infra</a>, <a href=../../category/devices/ class=md-meta__link>devices</a></li> <li class=md-meta__item> 需要 4 分钟阅读时间 </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=sdr><a href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/ class=toclink>软件定义无线电（SDR）的设备、软件与应用指南</a></h2> <p><a href=https://blog.lofyer.org/wp-content/uploads/www.youtube.com_watch_v-mks0TAwqQUlistPLbBQHMnVMR41tOomyB0o7UKAxwKINkFFnindex4.png><img alt src=/blog/images/www.youtube.com_watch_v-mks0TAwqQUlistPLbBQHMnVMR41tOomyB0o7UKAxwKINkFFnindex4.png></a></p> <p><strong>注意：本文内容仅限于实验室安全测试目的，禁止用于任何商业或违反当地法律法规的活动。</strong></p> <p><strong>不管是较贵的Ettus还是入门的HackRF，抑或是最初级的RTL-SDR设备，都可以使用这篇教程中的绝大部分内容。</strong></p> <p><a href="https://www.youtube.com/watch?v=Wt_c_H6HQAU&list=PLbBQHMnVMR41tOomyB0o7UKAxwKINkFFn">GRCon2019</a></p> <p>https://www.gnuradio.org/grcon/grcon17/presentations/</p> <p>https://www.gnuradio.org/grcon/grcon18/presentations/</p> <p>https://www.gnuradio.org/grcon/grcon19/presentations/</p> <p>https://github.com/mossmann/hackrf/wiki</p> <p>https://www.hackrf.net/hackrf%E4%B8%8Egnuradio%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/</p> <p>http://www.hackrf.net/faq/</p> <p>https://wiki.myriadrf.org/LimeSDR</p> <p>https://myriadrf.org/news/limesdr-made-simple-part-1/</p> <p><a href=https://blog.lofyer.org/software-defined-radio-device-software-application-guide/ >雪碧0xroot的PPT</a></p> <h2 id=0><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#0>0. 环境准备</a></h2> <h3 id=01><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#01>0.1 硬件</a></h3> <table> <thead> <tr> <th></th> <th>HackRF One</th> <th>Ettus B200</th> <th>Ettus B210</th> <th>BladeRF x40</th> <th>LimeSDR</th> <th>LimeSDR mini</th> </tr> </thead> <tbody> <tr> <td>Frequency Range</td> <td>1MHz-6GHz</td> <td>70MHz-6GHz</td> <td>70MHz-6GHz</td> <td>300MHz-3.8GHz</td> <td>100kHz-3.8GHz</td> <td>100kHz-3.5GHz</td> </tr> <tr> <td>RF Bandwidth</td> <td>20MHz</td> <td>61.44MHz</td> <td>61.44MHz</td> <td>40MHz</td> <td>61.44MHz</td> <td>30.72MHz</td> </tr> <tr> <td>Sample Depth</td> <td>8 bits</td> <td>12 bits</td> <td>12 bits</td> <td>12 bits</td> <td>12 bits</td> <td>12 bits</td> </tr> <tr> <td>Sample Rate</td> <td>20MSPS</td> <td>61.44MSPS</td> <td>61.44MSPS</td> <td>40MSPS</td> <td>3.2MSPS</td> <td>61.44MSPS</td> </tr> <tr> <td>Transmitter Channels</td> <td>1</td> <td>1</td> <td>2</td> <td>1</td> <td>2</td> <td>1</td> </tr> <tr> <td>Receivers</td> <td>1</td> <td>1</td> <td>2</td> <td>1</td> <td>2</td> <td>1</td> </tr> <tr> <td>Duplex</td> <td>Half</td> <td>Full</td> <td>Full</td> <td>Full</td> <td>Full</td> <td>Full</td> </tr> <tr> <td>Interface</td> <td>USB 2.0</td> <td>USB 3.0</td> <td>USB 3.0</td> <td>USB 3.0</td> <td>USB 3.0</td> <td>USB 3.0</td> </tr> <tr> <td>Programmable Logic Gates</td> <td>64 macrocell CPLD</td> <td>75k</td> <td>100k</td> <td>40k (115k avail)</td> <td>40k</td> <td>40k</td> </tr> <tr> <td>Chipset</td> <td>MAX5864, MAX2837, RFFC5072</td> <td>AD9364</td> <td>AD9361</td> <td>LMS6002M</td> <td>LMS7002M</td> <td>LMS7002M</td> </tr> <tr> <td>Open Source</td> <td>Full</td> <td>Schematic, Firmware</td> <td>Schematic, Firmware</td> <td>Schematic, Firmware</td> <td>Full</td> <td>Full</td> </tr> <tr> <td>Oscillator Precision</td> <td>+/-20ppm</td> <td>+/-2ppm</td> <td>+/-2ppm</td> <td>+/-1ppm</td> <td> +/-1ppm initial</td> <td></td> </tr> <tr> <td>+/-4ppm stable</td> <td> +/-1ppm initial</td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <p>+/-4ppm stable | | Transmit Power | -10dBm+ (15dBm @ 2.4GHz) | 10dBm+ | 10dBm+ | 6dBm |  0 to 10dBm | 0 to 10dBm | | Price | 249€ euros VAT Exc. | 991€ euros VAT Exc. | 1658€ euros VAT Exc. | 625€ euros VAT Exc. | 332€ euros VAT Exc. | 190€ euros VAT Exc. |</p> <h3 id=02><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#02>0.2 驱动</a></h3> <h3 id=03><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#03>0.3 软件</a></h3> <p>https://unicorn.360.com/blog/2017/04/12/LimeSDR-Getting-Started-Quickly/</p> <p>https://oneguyoneblog.com/2016/09/15/sdrsharp-sdr-installing-windows-10/</p> <p>下载SDR#后，重启按F7进入“禁用驱动签名”的运行模式，运行其中的install-rtlsdr.bat，替换第0个驱动</p> <h2 id=1><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#1>1. 接收信号</a></h2> <p>接收信号建议使用gqrx（MacOS、Linux），也可以用sdrsharp（Windows）。</p> <p>https://www.rtl-sdr.com/big-list-rtl-sdr-supported-software/</p> <p>$ port info gqrx</p> <p>$ sudo port install gqrx</p> <p>接收信号以后，你可以做的内容就比较多了，这里我会举一些比较有意思的例子。</p> <h3 id=11><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#11>1.1. 听广播/看电视</a></h3> <p>http://dalvikplanet.blogspot.com/2017/03/how-to-get-working-rtl2832u-r820t2-on.html</p> <h3 id=12><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#12>1.2. 接收气象云图</a></h3> <p>SDR软件</p> <p>虚拟声卡</p> <p>WXtoimg</p> <p>gpredict/orbitron</p> <p>https://www.rtl-sdr.com/rtl-sdr-tutorial-receiving-noaa-weather-satellite-/blog/images/</p> <p>https://wischu.com/archives/528.html</p> <p>GSM嗅探</p> <p>https://www.cnblogs.com/k1two2/p/7000942.html</p> <h3 id=13-gps><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#13-gps>1.3. 接收GPS信息</a></h3> <p>https://swling.com/blog/2016/04/guest-post-using-the-hackrf-one-for-dgps-beacon-reception/</p> <p>http://sdrgps.blogspot.com/2016/12/rtl-sdr-to-orbit-with-limesdr.html</p> <h3 id=14-direction-finding-and-passive-rador><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#14-direction-finding-and-passive-rador>1.4. 方向探测与被动雷达 Direction Finding and Passive Rador</a></h3> <p>https://www.rtl-sdr.com/ksdr/</p> <h3 id=15-whatever-you-want-legally><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#15-whatever-you-want-legally>1.5. 接收whatever you want LEGALLY</a></h3> <p>zigbee https://github.com/bastibl/gr-ieee802-15-4</p> <p>https://github.com/BastilleResearch/scapy-radio/tree/master/gnuradio/gr-zigbee</p> <h2 id=2><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#2>2. 发送信号</a></h2> <h3 id=21-gps><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#21-gps>2.1. 发送GPS信号</a></h3> <p>https://gist.github.com/gyaresu/343ae51ecbb70486e270</p> <p>https://www.cnblogs.com/k1two2/p/5477291.html#4245780</p> <p>https://gorgias.me/2017/07/30/HackRF-GPS-%E6%AC%BA%E9%AA%97/</p> <p>https://github.com/osqzss/LimeGPS</p> <h3 id=22><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#22>2.2. 发送文字/音视频</a></h3> <p>Windows软件sdrangel</p> <p>http://gareth.codes/hackrf-transmit/</p> <p>https://github.com/fsphil/hacktv</p> <p>http://www.irrational.net/2014/03/02/digital-atv/</p> <p>http://www.hackrf.net/2014/06/hackrf_nbfm_tx_n_ctcss_squelch/</p> <p>http://www.xn--hrdin-gra.se/blog/wp-content/uploads/2015/08/nbfm-tx.grc</p> <p>https://gist.github.com/gyaresu/343ae51ecbb70486e270</p> <p>https://nuclearrambo.com/wordpress/transferring-a-text-file-over-the-air-with-limesdr-mini/</p> <p>https://github.com/martinmarinov/TempestSDR</p> <h2 id=3><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#3>3. 收发信号</a></h2> <h3 id=gsm><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#gsm>GSM</a></h3> <p>https://www.evilsocket.net/2016/03/31/how-to-build-your-own-rogue-gsm-bts-for-fun-and-profit/</p> <p>https://yatebts.com/open_source/</p> <p>https://cn0xroot.com/2017/01/10/iot-mode-fuzzing-with-openbt/</p> <h3 id=lte><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#lte>LTE</a></h3> <p>https://yq.aliyun.com/articles/310348</p> <p>https://www.cnblogs.com/k1two2/p/5666667.html</p> <p>https://cn0xroot.com/2017/04/12/limesdr-getting-started-quickly/</p> <h3 id=openbtslimesdr><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#openbtslimesdr>OpenBTS+LimeSDR</a></h3> <p>Prepare:</p> <p>Ubuntu Desktop 16.04 &amp; LimeSDR 1.4s with <strong>LimeSuite 17.12(If not, OpenUSRP will fail.)</strong></p> <h4 id=install-build-essential-packages><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#install-build-essential-packages>Install build-essential packages</a></h4> <h2 id=packages-for-soapysdr-available-at-myriadrf-ppa><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#packages-for-soapysdr-available-at-myriadrf-ppa>packages for soapysdr available at myriadrf PPA</a></h2> <p>sudo add-apt-repository -y ppa:myriadrf/drivers sudo apt-get update</p> <h2 id=install-core-library-and-build-dependencies><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#install-core-library-and-build-dependencies>install core library and build dependencies</a></h2> <p>sudo apt-get install -y git g++ cmake libsqlite3-dev</p> <h2 id=install-hardware-support-dependencies><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#install-hardware-support-dependencies>install hardware support dependencies</a></h2> <p>sudo apt-get install -y libsoapysdr-dev libi2c-dev libusb-1.0-0-dev</p> <h2 id=install-graphics-dependencies><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#install-graphics-dependencies>install graphics dependencies</a></h2> <p>sudo apt-get install -y libwxgtk3.0-dev freeglut3-dev</p> <h2 id=install-for-building-uhd><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#install-for-building-uhd>Install for building uhd</a></h2> <p>sudo apt-get install libboost-all-dev libusb-1.0-0-dev python-mako doxygen python-docutils cmake build-essential</p> <h4 id=change-to-uhd-driver-via-uhd><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#change-to-uhd-driver-via-uhd>Change to UHD driver via uhd</a></h4> <p>$ cd ~ # build and install limesuite $ git clone https://github.com/myriadrf/LimeSuite.git $ cd LimeSuite $ mkdir builddir &amp;&amp; cd builddir $ cmake ../ $ make -j4 $ sudo make install $ sudo ldconfig</p> <p>$ cd ~ # build uhd, install, enable lime, rebuild $ git clone https://github.com/EttusResearch/uhd.git $ cd uhd/host/ $ mkdir build &amp;&amp; cd build $ cmake ../ $ make -j4 $ sudo make install $ git clone https://github.com/jocover/OpenUSRP.git lib/ursp/OpenUSRP # DO NOT GO OUT $ echo "INCLUDE_SUBDIRECTORY(OpenUSRP)"&gt;&gt;lib/ursp/CMakeLists.txt $ cmake ../ $ make -j4 $ sudo make install</p> <h4 id=or-change-to-uhd-driver-via-soapysdr><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#or-change-to-uhd-driver-via-soapysdr>Or, Change to UHD driver via SoapySDR</a></h4> <p>$ git clone https://github.com/pothosware/SoapySDR $ cd SoapySDR $ mkdir builddir;cd builddir; cmake ../ $ make -j4 $ sudo make install</p> <p>$ git clone https://github.com/myriadrf/LimeSuite $ cd LimeSuite</p> <h4 id=build-openbts><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#build-openbts>Build OpenBTS</a></h4> <h2 id=4-sdr><a class=toclink href=../../2019/05/10/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E6%97%A0%E7%BA%BF%E7%94%B5sdr%E7%9A%84%E8%AE%BE%E5%A4%87%E8%BD%AF%E4%BB%B6%E4%B8%8E%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97/#4-sdr>4. SDR</a></h2> <p>软件定义无线电的内容即是可以灵活定义信号的处理过程，比如输出到TCP/UDP、文字音视频解码等。其中比较有名的有GNURadio、SoapySDR、Pothos（IDE）等（这里以GNURadio为例）。推荐在Linux中安装，当然也可在MacOS或者Windows中使用MacPorts进行安装，除此之外，也有<a href=https://mirrors.tuna.tsinghua.edu.cn/help/pybombs/ >PyBombs</a>可选。</p> <p>在MacOS中安装需要使用MacPorts、XQuartz，MacPorts安装内容如下。</p> <p>$ port info gnuradio $ sudo port install gnuradio+wxgui gr-osmosdr sox $ port content gnuradio $ sudo port install hackrf $ sudo port install rtl-sdr $ sudo port search gr- # if you wanna more modules in gnuradio, don't be shy</p> <p>然后打开XQuartz，将/opt/local/bin/gnuradio-companion加入到X自定义应用程序菜单中（建议修改默认的X终端程序内容为_xterm -e "source ~/.bash_profile;/bin/bash"_）。</p> <p>https://greatscottgadgets.com/sdr/</p> <p>https://gist.github.com/machinaut/addf3438ef0c1a9cad38</p> <p>https://osmocom.org/projects/gr-osmosdr/wiki/GrOsmoSDR#RTL-SDRSource</p> <p>https://pypi.org/project/pyrtlsdr/#description</p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2019-04-08 00:00:00">2019年4月8日</time></li> <li class=md-meta__item> 分类于 <a href=../../category/ai/ class=md-meta__link>ai</a>, <a href=../../category/devices/ class=md-meta__link>devices</a></li> <li class=md-meta__item> 需要 7 分钟阅读时间 </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=nvidia-jetson><a href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/ class=toclink>NVIDIA Jetson使用指导</a></h2> <p>本文将以NVIDIA Jetson为硬件基础，为你展现NVIDIA的力量，可以将其作为Jetson Nano的入门参考手册（教程）。</p> <h3 id=1><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#1>1. 入门篇</a></h3> <p>入门篇的有两章内容，来自NVIDIA JETSON包装盒自带的内容。</p> <h4 id=11><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#11>1.1. 准备环境</a></h4> <p>Ref.1: <a href=https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit>https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit</a></p> <p>Ref.2: <a href=https://developer.nvidia.com/embedded/downloads>https://developer.nvidia.com/embedded/downloads</a></p> <p>这里我使用的是一个Jetson Nano开发板，起初我以为随便一个USB数据线就能把它跑起来，但是我想多了。18W的快充头插上后可以正常启动，但是一旦运行比如WebGL测试的页面直接就关机了，因而我把小米音箱的电源适配器（5V2A）给它用了，还真能跑的动。</p> <p>但是为了接下来的内容，我特意买了一个5V4A的5.5mm OD的电源适配器，要不然以我现在的环境很难保证能过了接下来的准备环境阶段。</p> <p>要使用这个板子，你需要提前下载<a href=https://developer.nvidia.com/embedded/dlc/jetson-nano-dev-kit-sd-card-image>SDK的SD卡镜像</a>，以及Host OS（PC，Ubuntu 18.04）所需的<a href=https://developer.nvidia.com/embedded/dlc/nv-sdk-manager>SDK Manager</a>。</p> <p>下载完成之后，从Ref.1的链接中下载所需的镜像烧录软件或者别的烧录软件也行，将SD卡镜像烧录至TF卡中（这里我使用的是64G TF卡，A2）。烧录完毕将其插入核心板下面的卡槽中（有些不好找），见下图。</p> <p><a href=https://blog.lofyer.org/wp-content/uploads/微信图片_20190411181357.jpg><img alt src=/blog/images/微信图片_20190411181357.jpg></a></p> <p>然后通过HDMI/DP线将之与显示器连接（启动阶段的分辨率需要修改，要不然小点的屏幕没法显示启动logo，这个不是重点以后再说），插上蓝牙USB键鼠，接入USB电源，你就可以看到信仰之NVIDIA logo。</p> <p><a href=https://blog.lofyer.org/wp-content/uploads/微信图片_20190411181347.jpg><img alt src=/blog/images/微信图片_20190411181347.jpg></a></p> <p>这里你需要等它初始化完成，初始化工作包括扩展跟文件系统、解压乱七八糟的包之类的，总之等看到Ubuntu Desktop的安装配置界面后可以开始操作了。</p> <p>进入桌面后的第一件事儿，可以先打开Chromium，访问<a href=https://webglsamples.org/ >WebGL的示例网站</a>，随便开个demo试试会不会关机，如果关机那么恭喜你可以找个正经的USB电源了（Ref.1里有Adafruit的USB和DC电源适配器购买链接）。</p> <p>当你的DC电源到了以后，先不要直接插上，因为需要设置一下跳线，如图所示。</p> <p><a href=https://blog.lofyer.org/wp-content/uploads/f449ce42a97d019b5225c7c220e72ba7.png><img alt src=/blog/images/f449ce42a97d019b5225c7c220e72ba7.png></a></p> <p>看到Power Jack/USB Jumper没，由于我手里没有跳线帽，所以我直接短接了它们，如图所示（看我意念焊接术）。</p> <p><a href=https://blog.lofyer.org/wp-content/uploads/微信图片编辑_20190411181008.jpg><img alt src=/blog/images/微信图片编辑_20190411181008.jpg></a></p> <p>然后再插上刚入手的DC 5V4A，即可空出你的USB并将之与Host PC相连了。</p> <h4 id=12-sdk><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#12-sdk>1.2. 准备SDK</a></h4> <p><strong>这一节你可以先跳过去，等跑完下面的小节后再看，因为这部分并不影响接下来的操作。</strong></p> <p>准备SDK的内容主要包括：下载安装Host PC、开发板所需CUDA、OpenCV之类的，需要开发板的USB连接到Host PC上作数据连接用（我没有尝试过那个USB口既作电源又作数据传输）。</p> <p><a href=https://blog.lofyer.org/wp-content/uploads/捕获-1.png><img alt src=/blog/images/捕获-1.png></a></p> <p>这里我并不打算过多介绍，只要按照引导进行操作即可。</p> <h4 id=13-hello-ai-world><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#13-hello-ai-world>1.3. Hello AI World</a></h4> <p>这个示例为你充分避开了各种依赖库的复杂安装步骤以及非常多的专业术语，对新手较为友好，但是我会仍会将其以链接形式展现，在最后章节的连接中。</p> <p>第一步，从Hello World开始，你仍然需要最基础的工具。</p> <p>$ sudo apt install git make cmake $ git clone https://github.com/dusty-nv/jetson-inference $ cd jetson-inference $ git submodule update --init $ mkdir build $ cd build $ cmake ../ $ make -j4 $ sudo make install $ cd aarch64/bin</p> <p>这一顿操作后，你会拥有个Hello AI World的全部成果。但是，what the hell an I doing?</p> <p>来，对于一些Linux不熟悉的同学来说只要知道这里的cmake与make是编译源码的指令就行，cmake用来生成Makefile，make会根据Makefile里定义的动作调用gcc开始编译。</p> <p>然后让我们看第一个例子，使用<a href=http://www.image-net.org/ >ImageNet</a>的图片素材来训练我们的“机器人”让它能够识别各种物体，其中你会看到当前目录下有两个imagenet开头的文件，让我们从imagenet-console开始。</p> <p>在图形界面上打开终端后，执行如下命令。</p> <p>$ ./imagenet-console orange_0.jpg output_0.jpg $ nautilus .</p> <p>然后经过机器人的推理以后，你会得到一张橘子、另一张还是橘子的图片，并且新橘子图片的左上角标识了机器人认为它有多大概率是橘子。</p> <p><img alt src=/blog/images/捕获.png></p> <p>是不是有感觉了？OK，我们继续。</p> <p>既然它可以看图片，那么它当然也可以看视频或者摄像头中的内容，那么接下来我们让它看到摄像头中的橘子试试。</p> <p>这里我需要给Jetson Nano接一个USB摄像头，接入以后可以在终端键入cheese打开拍照应用程序看它是否工作。</p> <p>然后终端中运行如下命令。</p> <p>./imagenet-camera</p> <p>Oops，segmentation fault了，<a href=https://github.com/dusty-nv/jetson-inference/blob/master/docs/imagenet-camera-2.md>如文档所说</a>，默认的摄像头是板载CSI摄像头，所以这里需要修改代码让它使用后来插入的USB摄像头。</p> <p>$ vi ../../../imagenet-camera/imagenet-camera.cpp</p> <p>...</p> <h2 id=include-imageneth><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#include-imageneth>include "imageNet.h"</a></h2> <h2 id=define-default_camera-0-1-for-onboard-camera-or-change-to-index-of-devvideo-v4l2-camera-0><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#define-default_camera-0-1-for-onboard-camera-or-change-to-index-of-devvideo-v4l2-camera-0>define DEFAULT_CAMERA 0 // -1 for onboard camera, or change to index of /dev/video V4L2 camera (&gt;=0)</a></h2> <p>bool signal_recieved = false; ...</p> <p>将DEFAULT_CAMERA修改为0以后，便会启用/dev/video0路径上的摄像头，然后重新编译。</p> <p>$ cd ../../ # build $ cmake ../ $ make -j4</p> <p>然后进到bin目录下再运行一次imagenet-camera即可。</p> <p><strong>PS：不是所有的摄像头都叫罗技C920，由于摄像头原生编码的问题，可能会导致上述程序黑屏，那么我们需要是适当修改一些内容。笔者暂时跳过这里，等改好以后再看。关于兼容列表可以参考<a href=https://elinux.org/Jetson_Nano#Ecosystem_Products_and_Sensors>eLinux的链接</a>。</strong></p> <h4 id=14><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#14>1.4. 写一个小程序</a></h4> <p>如果你跟着github的教程，那么应该到你自己写一段代码的时间了，直接粘贴吧。</p> <p>// include imageNet header for image recognition</p> <h2 id=include><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#include>include <jetson-inference imagenet.h></a></h2> <p>// // include loadImage header for loading images</p> <h2 id=include_1><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#include_1>include <jetson-utils loadimage.h></a></h2> <p>int main( int argc, char** argv ) { // a command line argument containing the image filename is expected, // // so make sure we have at least 2 args (the first arg is the program) if( argc &lt; 2 ) { printf("my-recognition: expected image filename as argument\n"); printf("example usage: ./my-recognition my_image.jpg\n"); return 0; }</p> <p>// retrieve the image filename from the array of command line args const char* imgFilename = argv[1]; float* imgCPU = NULL; // CPU pointer to floating-point RGBA image data float* imgCUDA = NULL; // GPU pointer to floating-point RGBA image data int imgWidth = 0; // width of the image (in pixels) int imgHeight = 0; // height of the image (in pixels)</p> <p>// load the image from disk as float4 RGBA (32 bits per channel, 128 bits per pixel) if( !loadImageRGBA(imgFilename, (float4**)&amp;imgCPU, (float4**)&amp;imgCUDA, &amp;imgWidth, &amp;imgHeight) ) { printf("failed to load image '%s'\n", imgFilename); return 0; } imageNet* net = imageNet::Create(imageNet::GOOGLENET);</p> <p>if( !net ) { printf("failed to load image recognition network\n"); return 0; } float confidence = 0.0; const int classIndex = net-&gt;Classify(imgCUDA, imgWidth, imgHeight, &amp;confidence); if( classIndex &gt;= 0 ) { // retrieve the name/description of the object class index const char* classDescription = net-&gt;GetClassDesc(classIndex); // print out the classification results printf("image is recognized as '%s' (class #%i) with %f%% confidence\n", classDescription, classIndex, confidence * 100.0f); } else { // if Classify() returned &lt; 0, an error occurred printf("failed to classify image\n"); } delete net; // this is the end of the example! return 0; }</p> <h2 id=require-cmake-28-or-greater><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#require-cmake-28-or-greater>require CMake 2.8 or greater</a></h2> <p>cmake_minimum_required(VERSION 2.8)</p> <h2 id=declare-my-recognition-project><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#declare-my-recognition-project>declare my-recognition project</a></h2> <p>project(my-recognition)</p> <h2 id=import-jetson-inference-and-jetson-utils-packages><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#import-jetson-inference-and-jetson-utils-packages>import jetson-inference and jetson-utils packages.</a></h2> <h2 id=note-that-if-you-didnt-do-sudo-make-install><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#note-that-if-you-didnt-do-sudo-make-install>note that if you didn't do "sudo make install"</a></h2> <h2 id=while-building-jetson-inference-this-will-error><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#while-building-jetson-inference-this-will-error>while building jetson-inference, this will error.</a></h2> <p>find_package(jetson-utils) find_package(jetson-inference)</p> <h2 id=cuda-and-qt4-are-required><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#cuda-and-qt4-are-required>CUDA and Qt4 are required</a></h2> <p>find_package(CUDA) find_package(Qt4)</p> <h2 id=setup-qt4-for-build><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#setup-qt4-for-build>setup Qt4 for build</a></h2> <p>include(<span qt_95_definitions=QT_DEFINITIONS class=arithmatex>\({QT\_USE\_FILE}) add\_definitions(\)</span>)</p> <h2 id=compile-the-my-recognition-program><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#compile-the-my-recognition-program>compile the my-recognition program</a></h2> <p>cuda_add_executable(my-recognition my-recognition.cpp)</p> <h2 id=link-my-recognition-to-jetson-inference-library><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#link-my-recognition-to-jetson-inference-library>link my-recognition to jetson-inference library</a></h2> <p>target_link_libraries(my-recognition jetson-inference)</p> <p>然后编译并运行。</p> <p>$ cmake . $ make $ ./my.cpp polarbear.jpg</p> <p>输出结果如下。</p> <p>[cuda] cudaAllocMapped 5089520 bytes, CPU 0x100c30000 GPU 0x100c30000</p> <p>imageNet -- loading classification network model from: -- prototxt networks/googlenet.prototxt -- model networks/bvlc_googlenet.caffemodel -- class_labels networks/ilsvrc12_synset_words.txt -- input_blob 'data' -- output_blob 'prob' -- batch_size 2</p> <p>[TRT] TensorRT version 5.0.6 [TRT] detected model format - caffe (extension '.caffemodel') [TRT] desired precision specified for GPU: FASTEST [TRT] requested fasted precision for device GPU without providing valid calibrator, disabling INT8 [TRT] native precisions detected for GPU: FP32, FP16 [TRT] selecting fastest native precision for GPU: FP16 [TRT] attempting to open engine cache file /usr/local/bin/networks/bvlc_googlenet.caffemodel.2.1.GPU.FP16.engine [TRT] loading network profile from engine cache... /usr/local/bin/networks/bvlc_googlenet.caffemodel.2.1.GPU.FP16.engine [TRT] device GPU, /usr/local/bin/networks/bvlc_googlenet.caffemodel loaded [TRT] device GPU, CUDA engine context initialized with 2 bindings [TRT] binding -- index 0 -- name 'data' -- type FP32 -- in/out INPUT -- # dims 3 -- dim #0 3 (CHANNEL) -- dim #1 224 (SPATIAL) -- dim #2 224 (SPATIAL) [TRT] binding -- index 1 -- name 'prob' -- type FP32 -- in/out OUTPUT -- # dims 3 -- dim #0 1000 (CHANNEL) -- dim #1 1 (SPATIAL) -- dim #2 1 (SPATIAL) [TRT] binding to input 0 data binding index: 0 [TRT] binding to input 0 data dims (b=2 c=3 h=224 w=224) size=1204224 [cuda] cudaAllocMapped 1204224 bytes, CPU 0x101310000 GPU 0x101310000 [TRT] binding to output 0 prob binding index: 1 [TRT] binding to output 0 prob dims (b=2 c=1000 h=1 w=1) size=8000 [cuda] cudaAllocMapped 8000 bytes, CPU 0x101440000 GPU 0x101440000 device GPU, /usr/local/bin/networks/bvlc_googlenet.caffemodel initialized. [TRT] networks/bvlc_googlenet.caffemodel loaded imageNet -- loaded 1000 class info entries networks/bvlc_googlenet.caffemodel initialized. class 0296 - 1.000000 (ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus) image is recognized as 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus' (class #296) with 100.000000% confidence</p> <p>简言之，程序使用ImageNet的图片配上GoogleNet的模型对你的图片进行推理，然后得出它认为这是北极熊的可能性。</p> <p>因为这篇文章的目的是入门，也就是带进来以后看哪个方向就自己看，所以相关数学知识在这里已经忽略了，如果你能写出厉害的理论paper又做出很厉害的工程实现，那么大牛就请继续往下过，顺便留个言交个朋友让我膜拜一下。你也可以查看文末的链接进一步扩展阅读什么是GoogleNet，什么是CNN，然后撸一遍机器学习、深度学习、强化学习啥的，也可能一路懵懂复习到信号与系统、高等数学，你要书的话我这还卖，另外我的学习笔记可以参阅<a href=https://datanote.readthedocs.io/zh/master/ >DataNote</a>。</p> <h3 id=2><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#2>2. 进阶篇</a></h3> <h3 id=21><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#21>2.1. 重新训练模型</a></h3> <h3 id=22><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#22>2.2. 作为推理节点</a></h3> <h3 id=23><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#23>2.3. 深度学习实验</a></h3> <h3 id=24-tensorflow><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#24-tensorflow>2.4. TensorFlow实验</a></h3> <p>安装TensorFlow</p> <p>$ sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev $ sudo apt-get install python3-pip $ sudo pip3 install -U pip $ sudo pip3 install -U numpy grpcio absl-py py-cpuinfo psutil portpicker six mock requests gast h5py astor termcolor protobuf keras-applications keras-preprocessing wrapt google-pasta $ sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v42 tensorflow-gpu==1.14.0+nv19.9</p> <p>https://devtalk.nvidia.com/default/topic/1048776/official-tensorflow-for-jetson-nano-/</p> <p>https://www.tensorflow.org/tutorials</p> <p>with jupyter</p> <h4 id=25-tensorrt><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#25-tensorrt>2.5. TensorRT实验</a></h4> <h3 id=3><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#3>3. 行业方案篇</a></h3> <p>太阳底下没有新东西，我发现把之前的笔记稍微整理点可以新开一个目录出一个系列，那么，这里我就直接写关键字吧，以后说不定又冒出什么新东西了呢。</p> <p>在继续之前，我们需要抓住一样内容，即凡是人类自己通过观察、模仿、学习可以获得的重复能力，机器/深度/强化等内容理论来说都可以帮你实现，即使是创造力。</p> <p>然后我们再讲方案，即在这个小小的盒子，它有多少能力，能干啥。</p> <h3 id=31><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#31>3.1. 边缘计算</a></h3> <p>工业现场</p> <p>计算转移</p> <p>CDN</p> <p>军用头戴</p> <h3 id=32><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#32>3.2. 云游戏</a></h3> <p>4K/8K/HDR/60FPS家用主机、服务端</p> <p>无主机头戴</p> <h3 id=33><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#33>3.3. 教学设备</a></h3> <p>甭管便宜的贵的只要带卡都能当教学设备，不信你看研究生论文有多少CUDA相关。</p> <h3 id=34><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#34>3.4. 残障辅助</a></h3> <p>手语翻译（<a href=https://github.com/EvilPort2/Sign-Language>https://github.com/EvilPort2/Sign-Language</a>），可按照中国残联手语进行训练（<a href=http://www.cdpf.org.cn/special/zgsy/node_305701.htm>http://www.cdpf.org.cn/special/zgsy/node_305701.htm</a>）。</p> <p>apt install python3-keras</p> <p>辅助视觉（物体/人脸识别后转语音）</p> <h2 id=_1><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#_1>参考：</a></h2> <h3 id=_2><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#_2>文献</a></h3> <p>[1] NVIDIA AI Two Days Demo: <a href=https://developer.nvidia.com/embedded/twodaystoademo>https://developer.nvidia.com/embedded/twodaystoademo</a></p> <p>[2] CNN Architecture: <a href=https://medium.com/@sidereal/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5>https://medium.com/@sidereal/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5</a></p> <p>[3] eLinux: <a href=https://www.elinux.org/Jetson>https://www.elinux.org/Jetson</a></p> <h3 id=_3><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#_3>术语</a></h3> <p>[1] ImageNet: <a href=http://image-net.org/download>http://image-net.org/download</a></p> <p>[2] TensorRT: <a href=https://developer.nvidia.com/tensorrt>https://developer.nvidia.com/tensorrt</a></p> <p>[3] DeepStream: <a href=https://developer.nvidia.com/deepstream-sdk>https://developer.nvidia.com/deepstream-sdk</a></p> <p>[4] cuDNN</p> <p>[5] PyTorch</p> <h3 id=6-nvdla><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#6-nvdla>[6] NVDLA</a></h3> <p>title: "向NVIDIA Jetson Nano中移植QEMU-KVM" date: 2019-04-14 categories: - "cloud-infra" - "devices"</p> <hr> <p>因为Jetson如果作为边缘设备，那么我们需要进一步探索虚拟化在其上的可能性，从而使FT有更容易的路线可走，还有既然它的芯片是PCIE的，那理应可以透传。</p> <p>参考：<a href=https://elinux.org/Jetson/Nano/Upstream>https://elinux.org/Jetson/Nano/Upstream</a></p> <p>什么build rootfs、uboot之类的就不要了，那是后期嵌入式的活，我们在现有环境上build kernel即可。</p> <h2 id=1_1><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#1_1>1. 准备环境</a></h2> <p>访问链接<a href=https://developer.nvidia.com/embedded/downloads>https://developer.nvidia.com/embedded/downloads</a>并下载源码包，包括Jetson自有以及L4T源码，也可以点击如下链接直接下载。</p> <p>https://developer.nvidia.com/embedded/dlc/l4t-sources-32-1-jetson-nano</p> <p>解压其中的kernel部分。</p> <p>https://developer.nvidia.com/embedded/dlc/l4t-jetson-driver-package-32-1-jetson-nano</p> <p>下载并解压后，得到如下文件系统。</p> <h2 id=2-kernel><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#2-kernel>2. 准备kernel</a></h2> <p>Host: sudo su sudo apt install nfs-kernel-server sudo echo "/home/lofyer/Downloads *(rw,no_root_squash,no_subtree_check)" &gt;&gt; /etc/exports sudo exportfs -avf</p> <p>Jetson Nano: sudo su apt instlal libncurses-dev mount root@192.168.0.59:/home/lofyer/Downloads /mnt cd /mnt/ cp /proc/config.gz . gunzip config.gz mv config .config make menuconfig # find and enable kvm, tegra hypervisor make -j4; make -j4 modules_install make -j4 Image cp arch/arm64/boot/Image /boot/Image-kvm</p> <p>然后编辑启动项，默认从新kernel启动。</p> <h2 id=vi-bootextlinuxextlinuxconf><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#vi-bootextlinuxextlinuxconf>vi /boot/extlinux/extlinux.conf</a></h2> <p>TIMEOUT 10 DEFAULT secondary</p> <p>MENU TITLE p3450-porg eMMC boot options</p> <p>LABEL primary MENU LABEL primary kernel LINUX /boot/Image INITRD /boot/initrd APPEND ${cbootargs} rootfstype=ext4 root=/dev/mmcblk0p1 rw rootwait</p> <p>LABEL secondary MENU LABEL kernel with kvm LINUX /boot/Image-kvm INITRD /boot/initrd APPEND ${cbootargs} rootfstype=ext4 root=/dev/mmcblk0p1 rw rootwait</p> <h2 id=3-qemu-kvm><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#3-qemu-kvm>3. 尝试qemu-kvm</a></h2> <p>自带的：</p> <p>apt install qemu-kvm kvm --help</p> <p>自己编的：</p> <p>git clone https://github.com/qemu/qemu cd qemu ./configure --enable-kvm make -j4</p> <p>只能使用machine类型为arm进行加速。</p> <h2 id=4-ft><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#4-ft>4. 看看FT</a></h2> <h3 id=_4><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#_4>算了，现在不看了，等下半年。</a></h3> <p>title: "基于ARM(NVIDIA-JETSON-NANO)编译NetLogo" date: 2019-04-06 categories: - "abm" - "devices" -tags: - "NVIDIA" - "Jetson Nano" - "NetLogo"</p> <hr> <p>本文主要目的为测试这块板子的性能，看看其是否有作为边缘节点的能力。</p> <h3 id=env><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#env>Env</a></h3> <p>Ubuntu 18.04(jetson-nano-sd-r32.1-2019-03-18)</p> <h3 id=prepare><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#prepare>Prepare</a></h3> <p>$ sudo set -i 's/ports.ubuntu.com/mirrors.ustc.edu.cn/g' /etc/apt/sources.list $ sudo apt install -y curl x11vnc openjdk openjfx libopenjfx-jni libopenjfx-java</p> <h3 id=build><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#build>Build</a></h3> <p>$ git clone https://github.com/NetLogo/NetLogo $ cd NetLogo $ git submodule update --init $ ./sbt netlogo/compile</p> <p>Run and Package</p> <p>$ ./sbt netlogo/run $ ./sbt dist/buildNetLogo</p> <h3 id=addon-add-vnc-server-to-your-board><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#addon-add-vnc-server-to-your-board>Addon: Add VNC server to your board</a></h3> <p>$ sudo apt install -y x11nvc $ x11vnc # to generate ~/.vnc files $ echo 'x11vnc --loop &amp;' &gt;&gt; ~/.xsessionrc</p> <h3 id=ref><a class=toclink href=../../2019/04/08/nvidia-jetson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AF%BC/#ref>Ref</a></h3> <p><a href=https://github.com/NetLogo/NetLogo/wiki/Building>https://github.com/NetLogo/NetLogo/wiki/Building</a></p> <p><a href=https://github.com/NetLogo/NetLogo/wiki/Releasing>https://github.com/NetLogo/NetLogo/wiki/Releasing</a></p> </div> </article> <nav class=md-pagination> </nav> </div> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2008 - 2024 lofyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["search.suggest", "search.highlight", "navigation.tabs", "navigation.tabs.sticky", "navigation.tracking", "navigation.prune", "navigation.instant", "navigation.instant.progess"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../../assets/javascripts/bundle.525ec568.min.js></script> <script src=../../../javascripts/config.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>