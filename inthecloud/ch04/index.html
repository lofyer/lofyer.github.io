<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content=lofyer><link href=https://docs.lofyer.org/inthecloud/ch04/ rel=canonical><link href=../ch03/ rel=prev><link href=../ch05/ rel=next><link rel=icon href=../../images/favicon.ico><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.34"><title>第四章 数据抓取与机器学习算法 - Lofyer's Blog</title><link rel=stylesheet href=../../assets/stylesheets/main.35f28582.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../.. title="Lofyer's Blog" class="md-header__button md-logo" aria-label="Lofyer's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Lofyer's Blog </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 第四章 数据抓取与机器学习算法 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=查找> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/lofyer/lofyer.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> lofyer/lofyer.github.io </div> </a> </div> </nav> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Index </a> </li> <li class=md-tabs__item> <a href=../../blog/ class=md-tabs__link> Blog </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../datanote/ class=md-tabs__link> Docs </a> </li> <li class=md-tabs__item> <a href=../../about/about/ class=md-tabs__link> About </a> </li> <li class=md-tabs__item> <a href=../../template_password/ class=md-tabs__link> [密码保护]Template </a> </li> <li class=md-tabs__item> <a href=../../tags/ class=md-tabs__link> Tags </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Lofyer's Blog" class="md-nav__button md-logo" aria-label="Lofyer's Blog" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> Lofyer's Blog </label> <div class=md-nav__source> <a href=https://github.com/lofyer/lofyer.github.io title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> lofyer/lofyer.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Index </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Docs </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Docs </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../datanote/ class=md-nav__link> <span class=md-ellipsis> DataNote </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2 checked> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> InTheCloud </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=true> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> InTheCloud </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> <span class=md-ellipsis> Index </span> </a> </li> <li class=md-nav__item> <a href=../ch01/ class=md-nav__link> <span class=md-ellipsis> 第一章 随便说些什么 </span> </a> </li> <li class=md-nav__item> <a href=../ch02/ class=md-nav__link> <span class=md-ellipsis> 第二章 一个可靠的存储后端 </span> </a> </li> <li class=md-nav__item> <a href=../ch03/ class=md-nav__link> <span class=md-ellipsis> 第三章 合适的虚拟化平台 </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 第四章 数据抓取与机器学习算法 </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 第四章 数据抓取与机器学习算法 </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#41 class=md-nav__link> <span class=md-ellipsis> 4.1 数据收集 </span> </a> <nav class=md-nav aria-label="4.1 数据收集"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 简单抓取 </span> </a> <nav class=md-nav aria-label=简单抓取> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 动手写一个最简单的爬虫 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 实际使用时遇到的问题 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 分布式抓取 </span> </a> <nav class=md-nav aria-label=分布式抓取> <ul class=md-nav__list> <li class=md-nav__item> <a href=#scrapyd class=md-nav__link> <span class=md-ellipsis> scrapyd </span> </a> </li> <li class=md-nav__item> <a href=#scrapy-redis class=md-nav__link> <span class=md-ellipsis> scrapy-redis </span> </a> </li> <li class=md-nav__item> <a href=#nutch-solr class=md-nav__link> <span class=md-ellipsis> 使用Nutch + Solr </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#42 class=md-nav__link> <span class=md-ellipsis> 4.2 爬虫示例 </span> </a> <nav class=md-nav aria-label="4.2 爬虫示例"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#58 class=md-nav__link> <span class=md-ellipsis> 58同城 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 知乎 </span> </a> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 新浪微博 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#43-numpy class=md-nav__link> <span class=md-ellipsis> 4.3 numpy 快查 </span> </a> </li> <li class=md-nav__item> <a href=#44-python class=md-nav__link> <span class=md-ellipsis> 4.4 监督学习常用算法及Python实现 </span> </a> <nav class=md-nav aria-label="4.4 监督学习常用算法及Python实现"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 信息分类基础 </span> </a> </li> <li class=md-nav__item> <a href=#k class=md-nav__link> <span class=md-ellipsis> K邻近算法 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 决策树 </span> </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 朴素贝叶斯 </span> </a> </li> <li class=md-nav__item> <a href=#logistic class=md-nav__link> <span class=md-ellipsis> Logistic回归 </span> </a> </li> <li class=md-nav__item> <a href=#svm class=md-nav__link> <span class=md-ellipsis> SVM </span> </a> </li> <li class=md-nav__item> <a href=#adaboost class=md-nav__link> <span class=md-ellipsis> AdaBoost </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#45 class=md-nav__link> <span class=md-ellipsis> 4.5 无监督学习 </span> </a> </li> <li class=md-nav__item> <a href=#46 class=md-nav__link> <span class=md-ellipsis> 4.6 数据可视化 </span> </a> <nav class=md-nav aria-label="4.6 数据可视化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 数据统计 </span> </a> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 地理位置表示 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#47 class=md-nav__link> <span class=md-ellipsis> 4.7 机器学习工具 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ch05/ class=md-nav__link> <span class=md-ellipsis> 第五章 数据处理平台 </span> </a> </li> <li class=md-nav__item> <a href=../appendix01/ class=md-nav__link> <span class=md-ellipsis> 附录一 OpenStack概念、部署、与高级网络应用 </span> </a> </li> <li class=md-nav__item> <a href=../appendix02/ class=md-nav__link> <span class=md-ellipsis> 附录二 公有云参考 </span> </a> </li> <li class=md-nav__item> <a href=../appendix03/ class=md-nav__link> <span class=md-ellipsis> 附录三 PaaS/OpenShif </span> </a> </li> <li class=md-nav__item> <a href=../appendix04/ class=md-nav__link> <span class=md-ellipsis> 附录四 Docker 使用及自建repo </span> </a> </li> <li class=md-nav__item> <a href=../appendix05/ class=md-nav__link> <span class=md-ellipsis> 附录五 常用功能运维工具 </span> </a> </li> <li class=md-nav__item> <a href=../appendix06/ class=md-nav__link> <span class=md-ellipsis> 附录六 文档参考资源以及建议书单 </span> </a> </li> <li class=md-nav__item> <a href=../appendix07/ class=md-nav__link> <span class=md-ellipsis> 待整理扩展内容 </span> </a> </li> <li class=md-nav__item> <a href=../about/ class=md-nav__link> <span class=md-ellipsis> 关于作者与文档 </span> </a> </li> <li class=md-nav__item> <a href=../frontline-network/ class=md-nav__link> <span class=md-ellipsis> 《运维前线》私有云桌面网络组建草稿 </span> </a> </li> <li class=md-nav__item> <a href=../frontline-storage/ class=md-nav__link> <span class=md-ellipsis> 《运维前线》虚拟化存储启动风暴草稿 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../wangsheng/ class=md-nav__link> <span class=md-ellipsis> WangSheng </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../about/about/ class=md-nav__link> <span class=md-ellipsis> About </span> </a> </li> <li class=md-nav__item> <a href=../../template_password/ class=md-nav__link> <span class=md-ellipsis> [密码保护]Template </span> </a> </li> <li class=md-nav__item> <a href=../../tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#41 class=md-nav__link> <span class=md-ellipsis> 4.1 数据收集 </span> </a> <nav class=md-nav aria-label="4.1 数据收集"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 简单抓取 </span> </a> <nav class=md-nav aria-label=简单抓取> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 动手写一个最简单的爬虫 </span> </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 实际使用时遇到的问题 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 分布式抓取 </span> </a> <nav class=md-nav aria-label=分布式抓取> <ul class=md-nav__list> <li class=md-nav__item> <a href=#scrapyd class=md-nav__link> <span class=md-ellipsis> scrapyd </span> </a> </li> <li class=md-nav__item> <a href=#scrapy-redis class=md-nav__link> <span class=md-ellipsis> scrapy-redis </span> </a> </li> <li class=md-nav__item> <a href=#nutch-solr class=md-nav__link> <span class=md-ellipsis> 使用Nutch + Solr </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#42 class=md-nav__link> <span class=md-ellipsis> 4.2 爬虫示例 </span> </a> <nav class=md-nav aria-label="4.2 爬虫示例"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#58 class=md-nav__link> <span class=md-ellipsis> 58同城 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 知乎 </span> </a> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 新浪微博 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#43-numpy class=md-nav__link> <span class=md-ellipsis> 4.3 numpy 快查 </span> </a> </li> <li class=md-nav__item> <a href=#44-python class=md-nav__link> <span class=md-ellipsis> 4.4 监督学习常用算法及Python实现 </span> </a> <nav class=md-nav aria-label="4.4 监督学习常用算法及Python实现"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 信息分类基础 </span> </a> </li> <li class=md-nav__item> <a href=#k class=md-nav__link> <span class=md-ellipsis> K邻近算法 </span> </a> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 决策树 </span> </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 朴素贝叶斯 </span> </a> </li> <li class=md-nav__item> <a href=#logistic class=md-nav__link> <span class=md-ellipsis> Logistic回归 </span> </a> </li> <li class=md-nav__item> <a href=#svm class=md-nav__link> <span class=md-ellipsis> SVM </span> </a> </li> <li class=md-nav__item> <a href=#adaboost class=md-nav__link> <span class=md-ellipsis> AdaBoost </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#45 class=md-nav__link> <span class=md-ellipsis> 4.5 无监督学习 </span> </a> </li> <li class=md-nav__item> <a href=#46 class=md-nav__link> <span class=md-ellipsis> 4.6 数据可视化 </span> </a> <nav class=md-nav aria-label="4.6 数据可视化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 数据统计 </span> </a> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 地理位置表示 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#47 class=md-nav__link> <span class=md-ellipsis> 4.7 机器学习工具 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=_1>第四章 数据抓取与机器学习算法</h1> <p>在开始这一章之前，你可能需要补习一下数学知识；还有熟悉下常见工具（语言），不必多年开发经验，会处理常见数据结构、能格式化文件即可。</p> <p>建议先通读一下 <a href=http://scrapy-chs.readthedocs.org/zh_CN/0.22/intro/overview.html>Scrapy 中文文档</a> ，这样你会省去好多Google的时间；在 <a href=http://www.zhihu.com/topic/19559424/top-answers>知乎</a> 上有许多关于 <em>大数据</em> 、 <em>数据挖掘</em> 的讨论，你可以去看看了解一些业内的动态。</p> <p>另外，可以使用 <a href=http://nutch.apache.org>Nutch</a> 来爬取，并用 <a href=http://lucene.apache.org/solr/ >Solr</a> 来构建一个简单的搜索引擎，它们可以跟下一章节的Hadoop集成。</p> <p>还有一个比较重要的点-- <a href=https://www.coursera.org/course/modelthinking>Model Thinking</a> ，你需要的不只是建模的知识，还要有建模的思想。数据和算法并不是最重要的，重要的是你如何利用这些数据通过你设计的模型来输出对你有用的结果。</p> <p><strong>不要以编程开始你的机器学习之旅，这样容易使思维受限于语言，从模型和结果思考去达到你的目的，编程只是手段之一。</strong></p> <h2 id=41>4.1 数据收集</h2> <p>数据收集是学习数据分析的开始。我们每一天</p> <p>为了省去一些学习的麻烦，我找了一些 <a href=http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public>“大”数据</a> ，有些上百TB的数据对非行业内的人来说可能毫无意义，但是，先来些数据吧，但是对学习者来说还是比较实用的。</p> <h3 id=_2>简单抓取</h3> <h4 id=_3>动手写一个最简单的爬虫</h4> <h4 id=_4>实际使用时遇到的问题</h4> <h3 id=_5>分布式抓取</h3> <h4 id=scrapyd>scrapyd</h4> <h4 id=scrapy-redis>scrapy-redis</h4> <h4 id=nutch-solr>使用Nutch + Solr</h4> <h2 id=42>4.2 爬虫示例</h2> <h3 id=58>58同城</h3> <p>我简单写了一个 <a href=https://github.com/lofyer/myspiders/tree/master/tongcheng>收集58同城中上海出租房信息的爬虫</a> ，包括的条目有： <em>描述</em> 、 <em>位置</em> 、 <em>价格</em> 、 <em>房间数</em> 、 <em>URL</em> 。</p> <p>由于这些信息都可以在地图上表示出来，那我除了画统计图以外还会画它们在地图上的表示。</p> <h3 id=_6>知乎</h3> <p><a href=http://blog.javachen.com/2014/06/08/using-scrapy-to-cralw-zhihu/ >http://blog.javachen.com/2014/06/08/using-scrapy-to-cralw-zhihu/</a></p> <p><a href=http://segmentfault.com/blog/javachen/1190000000583419>http://segmentfault.com/blog/javachen/1190000000583419</a></p> <p><a href=https://github.com/KeithYue/Zhihu_Spider.git>https://github.com/KeithYue/Zhihu_Spider.git</a></p> <h3 id=_7>新浪微博</h3> <p><a href=https://github.com/followyourheart/sina-weibo-crawler>https://github.com/followyourheart/sina-weibo-crawler</a></p> <h2 id=43-numpy>4.3 numpy 快查</h2> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span>
<span class=normal>44</span>
<span class=normal>45</span>
<span class=normal>46</span>
<span class=normal>47</span>
<span class=normal>48</span>
<span class=normal>49</span>
<span class=normal>50</span>
<span class=normal>51</span>
<span class=normal>52</span>
<span class=normal>53</span>
<span class=normal>54</span>
<span class=normal>55</span>
<span class=normal>56</span></pre></div></td><td class=code><div><pre><span></span><code>import numpy as np
a = np.arange(1,5)
data_type = [(&#39;name&#39;,&#39;S10&#39;), (&#39;height&#39;, &#39;float&#39;), (&#39;age&#39;, int)]
values = [(&#39;Arthur&#39;, 1.8, 41), (&#39;Lancelot&#39;, 1.9, 38),
            (&#39;Galahad&#39;, 1.7, 38)]
b = np.array(values, dtype=data_type)
c = np.arange(6,10)

# 符号
np.sign(a)

# 数组最大值
a.max()

# 数组最小值
a.max()

# 区间峰峰值
a.ptp()

# 乘积
a.prod()

# 累积
a.cumprod()

# 平均值
a.mean()

# 中值
a.median()

# 差分
np.diff(a)

# 方差
np.var(a)

# 元素条件查找，返回index的array
np.where(a&gt;2)

# 返回第2，3，5个元素的array
np.take(a, np.array(1,2,4))

# 排序
np.msort(a)
np.sort(b, kind=&#39;mergesort&#39;, order=&#39;height&#39;)

# 均分，奇数个元素的array不可分割为偶数。
np.split(b,2)

# 创建单位矩阵
np.eye(3)

# 最小二乘，参数为[x,y,degree]，degree为多项式的最高次幂，返回值为所有次幂的系数
np.polyfit(a,c,1)
</code></pre></div></td></tr></table></div> <h2 id=44-python>4.4 监督学习常用算法及Python实现</h2> <h3 id=_8>信息分类基础</h3> <p>信息的不稳定性为熵（entropy），而信息增益为有无样本特征对分类问题影响的大小。比如，抛硬币正反两面各有50%概率，此时不稳定性最大，熵为1；太阳明天照常升起，则是必然，此事不稳定性最小，熵为0。</p> <p>假设事件X，发生概率为x，其信息期望值定义为：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>l(X) = -log_2 x
</code></pre></div></td></tr></table></div> <p>整个信息的熵为：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>H = -\sum^n_{i=1} log_2 x
</code></pre></div></td></tr></table></div> <p>如何找到最好的分类特征：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span></pre></div></td><td class=code><div><pre><span></span><code>def chooseBestFeatureToSplit(dataSet):
    numFeatures = len(dataSet[0]) - 1      #the last column is used for the labels
    baseEntropy = calcShannonEnt(dataSet)
    bestInfoGain = 0.0; bestFeature = -1
    for i in range(numFeatures):        #iterate over all the features
        featList = [example[i] for example in dataSet]#create a list of all the examples of this feature
        uniqueVals = set(featList)       #get a set of unique values
        newEntropy = 0.0
        for value in uniqueVals:
            subDataSet = splitDataSet(dataSet, i, value)
            prob = len(subDataSet)/float(len(dataSet))
            newEntropy += prob * calcShannonEnt(subDataSet)
        infoGain = baseEntropy - newEntropy     #calculate the info gain; ie reduction in entropy
        if (infoGain &gt; bestInfoGain):       #compare this to the best gain so far
            bestInfoGain = infoGain         #if better than current best, set to best
            bestFeature = i
    return bestFeature                      #returns an integer

其中，dataSet为所有特征向量，caclShannonEnt()计算特征向量的熵，splitDataSet()切除向量中的value列；infoGain即为信息增益，chooseBestFeatureToSplit返回最好的特征向量索引值。
</code></pre></div></td></tr></table></div> <h3 id=k>K邻近算法</h3> <p>kNN的算法模型如下：</p> <p>对于未知类别属性的数据且集中的每个点依次执行以下操作：</p> <ul> <li>计算已知类别数据集中的点与当前点之间的距离</li> <li>按照距离递增依次排序</li> <li>选取与当前点距离最小的k个点</li> <li>确定前k个点所在类别的出现频率</li> <li>返回前k个点出现频率最高的类别作为当前点的预测分类</li> </ul> <p>代码参考如下：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span></pre></div></td><td class=code><div><pre><span></span><code>def classify0(inX, dataSet, labels, k):
    dataSetSize = dataSet.shape[0]
    diffMat = tile(inX, (dataSetSize,1)) - dataSet
    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis=1)
    distances = sqDistances**0.5
    sortedDistIndicies = distances.argsort()
    classCount={}
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1
    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)
    return sortedClassCount[0][0]

其中，inX为输入向量，dataSet为数据集，labels为数据集的分类，可调。距离计算公式为d0 = ((x-x0)**2 + (y-y0)**2)**0.5。
</code></pre></div></td></tr></table></div> <p>此种算法的优点为精度高、对异常值不敏感、但缺点也比较明显，即数据量大时开支相对较大，适用于数值－标称型数据。</p> <h3 id=_9>决策树</h3> <p>决策树即列出一系列选择，根据训练集中的大量形似（A、B、C）以及结果D的向量来预测新输入（A'、B'、C'）的结果D'。</p> <p>首先创建一个决策树：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span>
<span class=normal>20</span>
<span class=normal>21</span>
<span class=normal>22</span>
<span class=normal>23</span>
<span class=normal>24</span>
<span class=normal>25</span>
<span class=normal>26</span>
<span class=normal>27</span>
<span class=normal>28</span>
<span class=normal>29</span>
<span class=normal>30</span>
<span class=normal>31</span>
<span class=normal>32</span>
<span class=normal>33</span>
<span class=normal>34</span>
<span class=normal>35</span>
<span class=normal>36</span>
<span class=normal>37</span>
<span class=normal>38</span>
<span class=normal>39</span>
<span class=normal>40</span>
<span class=normal>41</span>
<span class=normal>42</span>
<span class=normal>43</span></pre></div></td><td class=code><div><pre><span></span><code> def createTree(dataSet,labels):
     classList = [example[-1] for example in dataSet]
     if classList.count(classList[0]) == len(classList):
         return classList[0]     #stop splitting when all of the classes are equal
     if len(dataSet[0]) == 1:    #stop splitting when there are no more features in dataSet
         return majorityCnt(classList)
     bestFeat = chooseBestFeatureToSplit(dataSet)
     bestFeatLabel = labels[bestFeat]
     myTree = {bestFeatLabel:{}}
     del(labels[bestFeat])
     featValues = [example[bestFeat] for example in dataSet]
     uniqueVals = set(featValues)
     for value in uniqueVals:
         subLabels = labels[:]       #copy all of labels, so trees don&#39;t mess up existing labels
         myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)
     return myTree

 找到影响最大的特征bestFeat后，再创建此特征下的分类向量创建子树向量，然后将bestFeat分离后继续迭代，直至所有特征都转换成决策节点。

 原始数据比如：

     no-surfacing flippers  fish
 1       yes         yes     yes
 2       yes         yes     yes
 3       yes         no      no
 4       no          yes     no
 5       no          yes     no

 会生成如下决策树：

 no-surfacing?
     /    \
  no/      \yes
fish(no)  flippers?
            / \
         no/   \yes
     fish(no)  fish(yes)

 表示成JSON格式，即python字典：

 {&#39;no surfacing&#39;:{0:&#39;no&#39;,1:{&#39;flippers&#39;:{0:&#39;no&#39;,1:&#39;yes&#39;}}}

 构建决策树的方法比较多，也可使用C4.5和CART算法。
</code></pre></div></td></tr></table></div> <p>接下来使用决策树进行分类：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span></pre></div></td><td class=code><div><pre><span></span><code>def classify(inputTree,featLabels,testVec):
    firstStr = inputTree.keys()[0]
    secondDict = inputTree[firstStr]
    featIndex = featLabels.index(firstStr)
    key = testVec[featIndex]
    valueOfFeat = secondDict[key]
    if isinstance(valueOfFeat, dict):
        classLabel = classify(valueOfFeat, featLabels, testVec)
    else: classLabel = valueOfFeat
    return classLabel

其中，featLabels为测试的判断节点，即特征，testVec为其值，比如classify[myTree,&quot;[&#39;no-surfacing&#39;,&#39;flippers&#39;]&quot;,:[1,1]&quot;]，如此结果便为&#39;no&#39;。
</code></pre></div></td></tr></table></div> <p>使用pickle对决策树进行序列化存储：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span>
<span class=normal>7</span></pre></div></td><td class=code><div><pre><span></span><code> def storeTree(inputTree,filename):
     import pickle
     fw = open(filename,&#39;w&#39;)
     pickle.dump(inputTree,fw)
     fw.close()

其中，dump可选协议为0（ASCII），1（BINARY），默认为0；读取时使用pickle.load；同样可使用dumps，loads直接对字符变量进行操作。
</code></pre></div></td></tr></table></div> <p>此种算法计算复杂度不高，对中间值缺失不敏感，但可能会产生过拟合的问题。</p> <h3 id=_10>朴素贝叶斯</h3> <p>贝叶斯模型是基于独立概率统计的，思想大概可以这么说：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span></pre></div></td><td class=code><div><pre><span></span><code>总共7个石子在A、B两个桶中，A桶中有2黑2白，B桶中有2黑1白。已知条件为石子来自B桶，那么它是白色石子的概率可表示为：

    P(white|B)=P(B|white)P(white)/P(B)

接下来，定义两个事件A、B，P(A|B)与P(B|A)相互转化的过程即为：

    P(B|A)=P(A|B)P(B)/P(A)

而朴素贝叶斯可以这样描述：

设x={a1,a2,...,am}为待分类项，a为x的特征属性，类别集合为C={y1,y2,...,ym}，如果P(yk|x)=max(P(y1|x),P(y2|x),...,P(yn|x))，则x属于yk。

整个算法核心即是等式P(yi|x)=P(x|yi)P(yi)/P(x)。
</code></pre></div></td></tr></table></div> <p>首先构建一个分类训练函数（二元分类）：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span>
<span class=normal>15</span>
<span class=normal>16</span>
<span class=normal>17</span>
<span class=normal>18</span>
<span class=normal>19</span></pre></div></td><td class=code><div><pre><span></span><code>def trainNB0(trainMatrix,trainCategory):
    numTrainDocs = len(trainMatrix)
    numWords = len(trainMatrix[0])
    pBad = sum(trainCategory)/float(numTrainDocs)
    p0Num = ones(numWords); p1Num = ones(numWords)      #change to ones()
    p0Denom = 2.0; p1Denom = 2.0                        #change to 2.0
    for i in range(numTrainDocs):
        if trainCategory[i] == 1:
            p1Num += trainMatrix[i]
            p1Denom += sum(trainMatrix[i])
        else:
            p0Num += trainMatrix[i]
            p0Denom += sum(trainMatrix[i])
    p1Vect = log(p1Num/p1Denom)          #change to log()
    p0Vect = log(p0Num/p0Denom)          #change to log()
    return p0Vect,p1Vect,pBad

其中，trainMatrix为所有训练集中的布尔向量，比如两本书A、B，其中A有两个单词x、y，B有两个单词x、z，并且A是好书（值计为0），B是烂书（值计为0），把所有单词进行排序后得向量[&#39;x&#39;,&#39;y&#39;,&#39;z&#39;]，则A的Matrix可表示为[1,1,0]，B的为[1,0,1]，所以此函数中的trainMatrix即[[1,1,0],[1,0,1]]，trainCategory为[0,1]。
函数返回的为概率集的向量。
</code></pre></div></td></tr></table></div> <p>分类函数：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span>
<span class=normal>7</span>
<span class=normal>8</span>
<span class=normal>9</span></pre></div></td><td class=code><div><pre><span></span><code>def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):
    p1 = sum(vec2Classify * p1Vec) + log(pClass1)    #element-wise mult
    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)
    if p1 &gt; p0:
        return 1
    else:
        return 0

vec2Classify即为要分类的向量，形如trainMatrix，随后的三个参数为trainNB0所返回。p1、p0可以理解为期望概率值，比较两者大小即可划分。
</code></pre></div></td></tr></table></div> <p>测试用例：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span></pre></div></td><td class=code><div><pre><span></span><code>def testingNB():
    listOPosts,listClasses = loadDataSet()
    myVocabList = createVocabList(listOPosts)
    trainMat=[]
    for postinDoc in listOPosts:
        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))
    p0V,p1V,pAb = trainNB0(array(trainMat),array(listClasses))
    testEntry = [&#39;love&#39;, &#39;my&#39;, &#39;dalmation&#39;]
    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))
    print testEntry,&#39;classified as: &#39;,classifyNB(thisDoc,p0V,p1V,pAb)
    testEntry = [&#39;stupid&#39;, &#39;garbage&#39;]
    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))
    print testEntry,&#39;classified as: &#39;,classifyNB(thisDoc,p0V,p1V,pAb)
</code></pre></div></td></tr></table></div> <p>整体来说，朴素贝叶斯分类方法在数据较少的情况下仍然有效，但是对数据输入比较敏感。</p> <h3 id=logistic>Logistic回归</h3> <p>在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。（ <a href=https://zh.wikipedia.org/zh-cn/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8>维基百科</a> ）</p> <p>先介绍两个重要的数学概念。</p> <p><strong>最小二乘法则</strong></p> <p>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。</p> <p>利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。</p> <p><em>示例1</em></p> <p>有四个数据点(1,6)、(2,5)、(3,7)、(4,10)，我们希望找到一条直线y=a+bx与这四个点最匹配。</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span>
<span class=normal>7</span></pre></div></td><td class=code><div><pre><span></span><code>a+1b=6

a+2b=5

a+3b=7

a+4b=10
</code></pre></div></td></tr></table></div> <p>采用最小二乘法使等号两边的方差尽可能小，也就是找出这个函数的最小值：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>S(a,b) = [6-(a+1b)]^2+[5-(a+2b)]^2+[7-(a+3b)]^2+[10-(a+4b)]^2
</code></pre></div></td></tr></table></div> <p>然后对S(a,b)求a,b的偏导数，使其为0得到：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span></pre></div></td><td class=code><div><pre><span></span><code>\cfrac{{\partial}S}{{\partial}a} = 0 = 8a+20b-56

\cfrac{{\partial}S}{{\partial}b} = 0 = 20a+60b-154
</code></pre></div></td></tr></table></div> <p>这样就解出：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>a=3.5,b=1.4
</code></pre></div></td></tr></table></div> <p>所以直线y=3.5+1.4x是最佳的。</p> <p><em>函数表示</em></p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>\min_{\vec{b}}{\sum^n_{i=1}}(y_m-y_i)^2
</code></pre></div></td></tr></table></div> <p><em>欧几里德表示</em></p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>\min_{ \vec{b} } \| \vec{y}_{m} ( \vec{b} ) - \vec{y} \|_{2}
</code></pre></div></td></tr></table></div> <p><em>线性函数模型</em></p> <p>典型的一类函数模型是线性函数模型。最简单的线性式是</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>y = b_0 + b_1 t
</code></pre></div></td></tr></table></div> <p>写成矩阵式，为</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>\min_{b_0,b_1}\left\|\begin{pmatrix}1 &amp; t_1 \\ \vdots &amp; \vdots \\ 1 &amp; t_n  \end{pmatrix}\begin{pmatrix} b_0\\ b_1\end{pmatrix} - \begin{pmatrix} y_1 \\ \vdots \\ y_{n}\end{pmatrix}\right\|_{2} = \min_b\|Ab-Y\|_2
</code></pre></div></td></tr></table></div> <p>直接给出该式的参数解：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span></pre></div></td><td class=code><div><pre><span></span><code>b_1 = \frac{\sum_{i=1}^n t_iy_i - n \cdot \bar t \bar y}{\sum_{i=1}^n t_i^2- n \cdot (\bar t)^2}

b_0 = \bar y - b_1 \bar t
</code></pre></div></td></tr></table></div> <p>其中</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>\bar t = \frac{1}{n} \sum_{i=1}^n t_i
</code></pre></div></td></tr></table></div> <p>为t值的算术平均值。也可解得如下形式：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>b_1 = \frac{\sum_{i=1}^n (t_i - \bar t)(y_i - \bar y)}{\sum_{i=1}^n (t_i - \bar t)^2}
</code></pre></div></td></tr></table></div> <p><em>示例2</em></p> <p>随机选定10艘战舰，并分析它们的长度与宽度，寻找它们长度与宽度之间的关系。由下面的描点图可以直观地看出，一艘战舰的长度（t）与宽度（y）基本呈线性关系。散点图如下：</p> <p>```{image} ../images/04-02.png :align: center</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span></pre></div></td><td class=code><div><pre><span></span><code>以下图表列出了各战舰的数据，随后步骤是采用最小二乘法确定两变量间的线性关系。

```{image} ../images/04-03.png
:align: center
</code></pre></div></td></tr></table></div> <p>仿照上面给出的例子</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>\bar t = \frac {\sum_{i=1}^n t_i}{n} = \frac {1678}{10} = 167{.}8
</code></pre></div></td></tr></table></div> <p>并得到相应的</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>\bar y = 18{.}41
</code></pre></div></td></tr></table></div> <p>然后确定b1</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span></pre></div></td><td class=code><div><pre><span></span><code>b_1 = \frac{\sum_{i=1}^n (t_i- \bar {t})(y_i - \bar y)}{\sum_{i=1}^n (t_i- \bar t)^2}

= \frac{3287{.}820} {20391{.}60} = 0{.}1612 \;
</code></pre></div></td></tr></table></div> <p>可以看出，战舰的长度每变化1m，相对应的宽度便要变化16cm。并由下式得到常数项b0：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>b_0 = \bar y - b_1 \bar t = 18{.}41 - 0{.}1612 \cdot 167{.}8 = -8{.}6394
</code></pre></div></td></tr></table></div> <p>可以看出点的拟合非常好，长度和宽度的相关性大约为96.03％。 利用Matlab得到拟合直线：</p> <p>```{image} ../images/04-04.png :align: center</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span>
<span class=normal>6</span>
<span class=normal>7</span></pre></div></td><td class=code><div><pre><span></span><code>**Sigmoid函数**

Sigmoid函数具有单位阶跃函数的性质，公式表示为：

```{math}

\sigma (z)=\cfrac{1}{1+e^{-z}}
</code></pre></div></td></tr></table></div> <p>```{image} ../images/04-01.png :align: center</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span>
<span class=normal>3</span>
<span class=normal>4</span>
<span class=normal>5</span></pre></div></td><td class=code><div><pre><span></span><code>我们将输入记为z，有下面的公式得出：

```{math}

z=w_0 x_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n
</code></pre></div></td></tr></table></div> <p>使用向量写法：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>z=w^T x
</code></pre></div></td></tr></table></div> <p>其中向量x是分类器的输入数据，向量w就是我们要找到的最佳系数。</p> <p><em>基于优化方法确定回归系数</em></p> <p><strong>梯度上升/下降法</strong></p> <p>梯度上升法/下降法的思想是：要找到函数的最大值，最好的方法是沿着该函数的梯度方向探寻，函数f(x,y)的梯度如下表示：</p> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span></pre></div></td><td class=code><div><pre><span></span><code>{\nabla}f(x,y)=\begin{pmatrix} \cfrac{{\partial}f(x,y)}{{\partial}x} \\ \cfrac{{\partial}f(x,y)}{{\partial}y}\end{pmatrix}
</code></pre></div></td></tr></table></div> <p>可以这样理解此算法：</p> <blockquote> <p>从前有一座山，一个懒人要爬山，他从山脚下的任意位置向山顶出发，并且知道等高线图的每个环上都有一个宿营点，他希望在这些宿营点之间修建一条笔直的路，并且路到两旁的宿营点的垂直距离差的平方和尽可能小。每到一个等高线圈，他都会根据他在上一个等高线的距离的变化量来调节他的在等高线上的位置，从而使公路满足要求。</p> <p>返回回归系数：</p> </blockquote> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal> 1</span>
<span class=normal> 2</span>
<span class=normal> 3</span>
<span class=normal> 4</span>
<span class=normal> 5</span>
<span class=normal> 6</span>
<span class=normal> 7</span>
<span class=normal> 8</span>
<span class=normal> 9</span>
<span class=normal>10</span>
<span class=normal>11</span>
<span class=normal>12</span>
<span class=normal>13</span>
<span class=normal>14</span></pre></div></td><td class=code><div><pre><span></span><code>def gradAscent(dataMatIn, classLabels):
    dataMatrix = mat(dataMatIn)             #convert to NumPy matrix
    labelMat = mat(classLabels).transpose() #convert to NumPy matrix
    m,n = shape(dataMatrix)
    alpha = 0.001
    maxCycles = 500
    weights = ones((n,1))
    for k in range(maxCycles):              #heavy on matrix operations
        h = sigmoid(dataMatrix*weights)     #matrix mult
        error = (labelMat - h)              #vector subtraction
        weights = weights + alpha * dataMatrix.transpose()* error #matrix mult
    return weights

其中，误差值乘以矩阵的转秩代表梯度。
</code></pre></div></td></tr></table></div> <p>待修改。</p> <h3 id=svm>SVM</h3> <p>SVM（Supprot Vector Machines）即支持向量机，完全理解其理论知识对数学要求较高。</p> <h3 id=adaboost>AdaBoost</h3> <h2 id=45>4.5 无监督学习</h2> <h2 id=46>4.6 数据可视化</h2> <h3 id=_11>数据统计</h3> <p>Gephi</p> <p>GraphViz</p> <p>python-matplotlib</p> <p>Microsoft Excel 2013 PowerView</p> <h3 id=_12>地理位置表示</h3> <p><a href="http://developer.baidu.com/map/index.php?title=%E9%A6%96%E9%A1%B5">百度地图API</a></p> <p><a href=http://dev.maxmind.com/geoip/geoip2/geolite2/ >MaxMind GeoIP</a></p> <p>Microsoft Excel 2013 PowerView使用示例</p> <h2 id=47>4.7 机器学习工具</h2> <p><a href=http://www.cs.waikato.ac.nz/ >Weka</a></p> <p><a href=https://ccl.northwestern.edu/netlogo/ >Netlogo</a></p> <p><a href=http://scikit-learn.org/ >SciKit</a></p> <p><a href=http://pandas.pydata.org/ >Pandas</a></p> <div id=disqus_thread></div> <script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://docs-lofyer-org.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
  </script> <noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2008 - 2022 lofyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["search.suggest", "search.highlight", "navigation.tabs", "navigation.tabs.sticky", "navigation.tracking", "navigation.prune"], "search": "../../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../assets/javascripts/bundle.56dfad97.min.js></script> <script src=../../javascripts/config.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>