<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content=lofyer><link href=https://docs.lofyer.org/datanote/ch02/ rel=canonical><link rel=icon href=../../images/favicon.ico><meta name=generator content="mkdocs-1.2.2, mkdocs-material-7.1.10"><title>第二章 机器学习基础 - Lofyer's Docs</title><link rel=stylesheet href=../../assets/stylesheets/main.1fe995fd.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.f1a3b89f.min.css></head> <body dir=ltr data-md-color-scheme data-md-color-primary=none data-md-color-accent=none> <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Lofyer's Docs" class="md-header__button md-logo" aria-label="Lofyer's Docs" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Lofyer's Docs </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 第二章 机器学习基础 </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/lofyer/lofyer.github.io title="前往 GitHub 仓库" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> lofyer/lofyer.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../ class="md-tabs__link md-tabs__link--active"> DataNote </a> </li> <li class=md-tabs__item> <a href=../../inthecloud/ class=md-tabs__link> InTheCloud </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Lofyer's Docs" class="md-nav__button md-logo" aria-label="Lofyer's Docs" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg> </a> Lofyer's Docs </label> <div class=md-nav__source> <a href=https://github.com/lofyer/lofyer.github.io title="前往 GitHub 仓库" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> lofyer/lofyer.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2> DataNote <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=DataNote data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> DataNote </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ class=md-nav__link> Index </a> </li> <li class=md-nav__item> <a href=../ch01/ class=md-nav__link> 第一章 数据收集、统计 </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> 第二章 机器学习基础 <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> 第二章 机器学习基础 </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#21-numpy class=md-nav__link> 2.1 numpy 快查 </a> </li> <li class=md-nav__item> <a href=#22 class=md-nav__link> 2.2 监督学习 </a> <nav class=md-nav aria-label="2.2 监督学习"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> 信息分类基础 </a> </li> <li class=md-nav__item> <a href=#k class=md-nav__link> K邻近算法 </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> 决策树 </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> 朴素贝叶斯 </a> </li> <li class=md-nav__item> <a href=#logistic class=md-nav__link> Logistic回归 </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> 线性回归 </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> 树回归 </a> </li> <li class=md-nav__item> <a href=#svm class=md-nav__link> SVM </a> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> 神经网络（深度学习） </a> </li> <li class=md-nav__item> <a href=#_8 class=md-nav__link> 强化学习 </a> </li> <li class=md-nav__item> <a href=#adaboost class=md-nav__link> AdaBoost </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#23 class=md-nav__link> 2.3 无监督学习 </a> <nav class=md-nav aria-label="2.3 无监督学习"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#k- class=md-nav__link> K-均值聚类 </a> </li> <li class=md-nav__item> <a href=#apriori class=md-nav__link> Apriori关联分析 </a> </li> <li class=md-nav__item> <a href=#fp-growth class=md-nav__link> FP-growth发现高频项 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#24 class=md-nav__link> 2.4 数据可视化 </a> <nav class=md-nav aria-label="2.4 数据可视化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_9 class=md-nav__link> 数据统计 </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> 地理位置表示 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#25 class=md-nav__link> 2.5 学习工具 </a> <nav class=md-nav aria-label="2.5 学习工具"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#online class=md-nav__link> Online </a> </li> <li class=md-nav__item> <a href=#gui class=md-nav__link> GUI </a> </li> <li class=md-nav__item> <a href=#library class=md-nav__link> Library </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#26 class=md-nav__link> 2.6 显卡的力量 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ch03/ class=md-nav__link> 第三章 ABM建模基础 </a> </li> <li class=md-nav__item> <a href=../ch04/ class=md-nav__link> 第四章 数据处理平台 </a> </li> <li class=md-nav__item> <a href=../ch05/ class=md-nav__link> 第五章 外汇交易基础 </a> </li> <li class=md-nav__item> <a href=../ch06/ class=md-nav__link> 第六章 信号交易系统 </a> </li> <li class=md-nav__item> <a href=../ch07/ class=md-nav__link> 第七章 指导白皮书 </a> </li> <li class=md-nav__item> <a href=../ch08/ class=md-nav__link> 第八章 代理人模型 </a> </li> <li class=md-nav__item> <a href=../ch08/ class=md-nav__link> 第八章 区块链货币套利模型 </a> </li> <li class=md-nav__item> <a href=../about/ class=md-nav__link> 关于 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3> InTheCloud <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=InTheCloud data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> InTheCloud </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../inthecloud/ class=md-nav__link> Index </a> </li> <li class=md-nav__item> <a href=../../inthecloud/ch01/ class=md-nav__link> 第一章 随便说些什么 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/ch02/ class=md-nav__link> 第二章 一个可靠的存储后端 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/ch03/ class=md-nav__link> 第三章 合适的虚拟化平台 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/ch04/ class=md-nav__link> 第四章 数据抓取与机器学习算法 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/ch05/ class=md-nav__link> 第五章 数据处理平台 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/appendix01/ class=md-nav__link> 附录一 OpenStack概念、部署、与高级网络应用 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/appendix02/ class=md-nav__link> 附录二 公有云参考 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/appendix03/ class=md-nav__link> 附录三 PaaS/OpenShif </a> </li> <li class=md-nav__item> <a href=../../inthecloud/appendix04/ class=md-nav__link> 附录四 Docker 使用及自建repo </a> </li> <li class=md-nav__item> <a href=../../inthecloud/appendix05/ class=md-nav__link> 附录五 常用功能运维工具 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/appendix06/ class=md-nav__link> 附录六 文档参考资源以及建议书单 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/appendix07/ class=md-nav__link> 待整理扩展内容 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/about/ class=md-nav__link> 关于作者与文档 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/frontline-network/ class=md-nav__link> 《运维前线》私有云桌面网络组建草稿 </a> </li> <li class=md-nav__item> <a href=../../inthecloud/frontline-storage/ class=md-nav__link> 《运维前线》虚拟化存储启动风暴草稿 </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#21-numpy class=md-nav__link> 2.1 numpy 快查 </a> </li> <li class=md-nav__item> <a href=#22 class=md-nav__link> 2.2 监督学习 </a> <nav class=md-nav aria-label="2.2 监督学习"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> 信息分类基础 </a> </li> <li class=md-nav__item> <a href=#k class=md-nav__link> K邻近算法 </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> 决策树 </a> </li> <li class=md-nav__item> <a href=#_4 class=md-nav__link> 朴素贝叶斯 </a> </li> <li class=md-nav__item> <a href=#logistic class=md-nav__link> Logistic回归 </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> 线性回归 </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> 树回归 </a> </li> <li class=md-nav__item> <a href=#svm class=md-nav__link> SVM </a> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> 神经网络（深度学习） </a> </li> <li class=md-nav__item> <a href=#_8 class=md-nav__link> 强化学习 </a> </li> <li class=md-nav__item> <a href=#adaboost class=md-nav__link> AdaBoost </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#23 class=md-nav__link> 2.3 无监督学习 </a> <nav class=md-nav aria-label="2.3 无监督学习"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#k- class=md-nav__link> K-均值聚类 </a> </li> <li class=md-nav__item> <a href=#apriori class=md-nav__link> Apriori关联分析 </a> </li> <li class=md-nav__item> <a href=#fp-growth class=md-nav__link> FP-growth发现高频项 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#24 class=md-nav__link> 2.4 数据可视化 </a> <nav class=md-nav aria-label="2.4 数据可视化"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_9 class=md-nav__link> 数据统计 </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> 地理位置表示 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#25 class=md-nav__link> 2.5 学习工具 </a> <nav class=md-nav aria-label="2.5 学习工具"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#online class=md-nav__link> Online </a> </li> <li class=md-nav__item> <a href=#gui class=md-nav__link> GUI </a> </li> <li class=md-nav__item> <a href=#library class=md-nav__link> Library </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#26 class=md-nav__link> 2.6 显卡的力量 </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=_1>第二章 机器学习基础</h1> <h2 id=21-numpy>2.1 numpy 快查</h2> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
<span class=n>a</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>5</span><span class=p>)</span>
<span class=n>data_type</span> <span class=o>=</span> <span class=p>[(</span><span class=s1>&#39;name&#39;</span><span class=p>,</span><span class=s1>&#39;S10&#39;</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;height&#39;</span><span class=p>,</span> <span class=s1>&#39;float&#39;</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;age&#39;</span><span class=p>,</span> <span class=nb>int</span><span class=p>)]</span>
<span class=n>values</span> <span class=o>=</span> <span class=p>[(</span><span class=s1>&#39;Arthur&#39;</span><span class=p>,</span> <span class=mf>1.8</span><span class=p>,</span> <span class=mi>41</span><span class=p>),</span> <span class=p>(</span><span class=s1>&#39;Lancelot&#39;</span><span class=p>,</span> <span class=mf>1.9</span><span class=p>,</span> <span class=mi>38</span><span class=p>),</span>
            <span class=p>(</span><span class=s1>&#39;Galahad&#39;</span><span class=p>,</span> <span class=mf>1.7</span><span class=p>,</span> <span class=mi>38</span><span class=p>)]</span>
<span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>values</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>data_type</span><span class=p>)</span>
<span class=n>c</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>6</span><span class=p>,</span><span class=mi>10</span><span class=p>)</span>

<span class=c1># 符号</span>
<span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>

<span class=c1># 数组最大值</span>
<span class=n>a</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>

<span class=c1># 数组最小值</span>
<span class=n>a</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>

<span class=c1># 区间峰峰值</span>
<span class=n>a</span><span class=o>.</span><span class=n>ptp</span><span class=p>()</span>

<span class=c1># 乘积</span>
<span class=n>a</span><span class=o>.</span><span class=n>prod</span><span class=p>()</span>

<span class=c1># 累积</span>
<span class=n>a</span><span class=o>.</span><span class=n>cumprod</span><span class=p>()</span>

<span class=c1># 平均值</span>
<span class=n>a</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

<span class=c1># 中值</span>
<span class=n>a</span><span class=o>.</span><span class=n>median</span><span class=p>()</span>

<span class=c1># 差分</span>
<span class=n>np</span><span class=o>.</span><span class=n>diff</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>

<span class=c1># 方差</span>
<span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>

<span class=c1># 元素条件查找，返回index的array</span>
<span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>a</span><span class=o>&gt;</span><span class=mi>2</span><span class=p>)</span>

<span class=c1># 返回第2，3，5个元素的array</span>
<span class=n>np</span><span class=o>.</span><span class=n>take</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>2</span><span class=p>,</span><span class=mi>4</span><span class=p>))</span>

<span class=c1># 排序</span>
<span class=n>np</span><span class=o>.</span><span class=n>msort</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>
<span class=n>np</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>b</span><span class=p>,</span> <span class=n>kind</span><span class=o>=</span><span class=s1>&#39;mergesort&#39;</span><span class=p>,</span> <span class=n>order</span><span class=o>=</span><span class=s1>&#39;height&#39;</span><span class=p>)</span>

<span class=c1># 均分，奇数个元素的array不可分割为偶数。</span>
<span class=n>np</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>b</span><span class=p>,</span><span class=mi>2</span><span class=p>)</span>

<span class=c1># 创建单位矩阵</span>
<span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>

<span class=c1># 最小二乘，参数为[x,y,degree]，degree为多项式的最高次幂，返回值为所有次幂的系数</span>
<span class=n>np</span><span class=o>.</span><span class=n>polyfit</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=n>c</span><span class=p>,</span><span class=mi>1</span><span class=p>)</span>
</code></pre></div> </td></tr></table> <h2 id=22>2.2 监督学习</h2> <h3 id=_2>信息分类基础</h3> <p>信息的不稳定性为熵（entropy），而信息增益为有无样本特征对分类问题影响的大小。比如，抛硬币正反两面各有50%概率，此时不稳定性最大，熵为1；太阳明天照常升起，则是必然，此事不稳定性最小，熵为0。</p> <p>假设事件X，发生概率为x，其信息期望值定义为：</p> <div class=arithmatex>\[ l(X) = -log_2 x \]</div> <p>整个信息的熵为：</p> <div class=arithmatex>\[ H = -\sum^n_{i=1} log_2 x \]</div> <p>如何找到最好的分类特征：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>chooseBestFeatureToSplit</span><span class=p>(</span><span class=n>dataSet</span><span class=p>):</span>
    <span class=n>numFeatures</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataSet</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=o>-</span> <span class=mi>1</span>      <span class=c1>#the last column is used for the labels</span>
    <span class=n>baseEntropy</span> <span class=o>=</span> <span class=n>calcShannonEnt</span><span class=p>(</span><span class=n>dataSet</span><span class=p>)</span>
    <span class=n>bestInfoGain</span> <span class=o>=</span> <span class=mf>0.0</span><span class=p>;</span> <span class=n>bestFeature</span> <span class=o>=</span> <span class=o>-</span><span class=mi>1</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>numFeatures</span><span class=p>):</span>        <span class=c1>#iterate over all the features</span>
        <span class=n>featList</span> <span class=o>=</span> <span class=p>[</span><span class=n>example</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>example</span> <span class=ow>in</span> <span class=n>dataSet</span><span class=p>]</span><span class=c1>#create a list of all the examples of this feature</span>
        <span class=n>uniqueVals</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>featList</span><span class=p>)</span>       <span class=c1>#get a set of unique values</span>
        <span class=n>newEntropy</span> <span class=o>=</span> <span class=mf>0.0</span>
        <span class=k>for</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>uniqueVals</span><span class=p>:</span>
            <span class=n>subDataSet</span> <span class=o>=</span> <span class=n>splitDataSet</span><span class=p>(</span><span class=n>dataSet</span><span class=p>,</span> <span class=n>i</span><span class=p>,</span> <span class=n>value</span><span class=p>)</span>
            <span class=n>prob</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>subDataSet</span><span class=p>)</span><span class=o>/</span><span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataSet</span><span class=p>))</span>
            <span class=n>newEntropy</span> <span class=o>+=</span> <span class=n>prob</span> <span class=o>*</span> <span class=n>calcShannonEnt</span><span class=p>(</span><span class=n>subDataSet</span><span class=p>)</span>
        <span class=n>infoGain</span> <span class=o>=</span> <span class=n>baseEntropy</span> <span class=o>-</span> <span class=n>newEntropy</span>     <span class=c1>#calculate the info gain; ie reduction in entropy</span>
        <span class=k>if</span> <span class=p>(</span><span class=n>infoGain</span> <span class=o>&gt;</span> <span class=n>bestInfoGain</span><span class=p>):</span>       <span class=c1>#compare this to the best gain so far</span>
            <span class=n>bestInfoGain</span> <span class=o>=</span> <span class=n>infoGain</span>         <span class=c1>#if better than current best, set to best</span>
            <span class=n>bestFeature</span> <span class=o>=</span> <span class=n>i</span>
    <span class=k>return</span> <span class=n>bestFeature</span>                      <span class=c1>#returns an integer</span>

<span class=n>其中</span><span class=err>，</span><span class=n>dataSet为所有特征向量</span><span class=err>，</span><span class=n>caclShannonEnt</span><span class=p>()</span><span class=n>计算特征向量的熵</span><span class=err>，</span><span class=n>splitDataSet</span><span class=p>()</span><span class=n>切除向量中的value列</span><span class=err>；</span><span class=n>infoGain即为信息增益</span><span class=err>，</span><span class=n>chooseBestFeatureToSplit返回最好的特征向量索引值</span><span class=err>。</span>
</code></pre></div> </td></tr></table> <h3 id=k>K邻近算法</h3> <p>kNN的算法模型如下：</p> <p>对于未知类别属性的数据且集中的每个点依次执行以下操作：</p> <ul> <li>计算已知类别数据集中的点与当前点之间的距离</li> <li>按照距离递增依次排序</li> <li>选取与当前点距离最小的k个点</li> <li>确定前k个点所在类别的出现频率</li> <li>返回前k个点出现频率最高的类别作为当前点的预测分类</li> </ul> <p>代码参考如下：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>classify0</span><span class=p>(</span><span class=n>inX</span><span class=p>,</span> <span class=n>dataSet</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>k</span><span class=p>):</span>
    <span class=n>dataSetSize</span> <span class=o>=</span> <span class=n>dataSet</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
    <span class=n>diffMat</span> <span class=o>=</span> <span class=n>tile</span><span class=p>(</span><span class=n>inX</span><span class=p>,</span> <span class=p>(</span><span class=n>dataSetSize</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span> <span class=o>-</span> <span class=n>dataSet</span>
    <span class=n>sqDiffMat</span> <span class=o>=</span> <span class=n>diffMat</span><span class=o>**</span><span class=mi>2</span>
    <span class=n>sqDistances</span> <span class=o>=</span> <span class=n>sqDiffMat</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>distances</span> <span class=o>=</span> <span class=n>sqDistances</span><span class=o>**</span><span class=mf>0.5</span>
    <span class=n>sortedDistIndicies</span> <span class=o>=</span> <span class=n>distances</span><span class=o>.</span><span class=n>argsort</span><span class=p>()</span>
    <span class=n>classCount</span><span class=o>=</span><span class=p>{}</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>k</span><span class=p>):</span>
        <span class=n>voteIlabel</span> <span class=o>=</span> <span class=n>labels</span><span class=p>[</span><span class=n>sortedDistIndicies</span><span class=p>[</span><span class=n>i</span><span class=p>]]</span>
        <span class=n>classCount</span><span class=p>[</span><span class=n>voteIlabel</span><span class=p>]</span> <span class=o>=</span> <span class=n>classCount</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>voteIlabel</span><span class=p>,</span><span class=mi>0</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span>
    <span class=n>sortedClassCount</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>classCount</span><span class=o>.</span><span class=n>iteritems</span><span class=p>(),</span> <span class=n>key</span><span class=o>=</span><span class=n>operator</span><span class=o>.</span><span class=n>itemgetter</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>sortedClassCount</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>

<span class=n>其中</span><span class=err>，</span><span class=n>inX为输入向量</span><span class=err>，</span><span class=n>dataSet为数据集</span><span class=err>，</span><span class=n>labels为数据集的分类</span><span class=err>，</span><span class=n>可调</span><span class=err>。</span><span class=n>距离计算公式为d0</span> <span class=o>=</span> <span class=p>((</span><span class=n>x</span><span class=o>-</span><span class=n>x0</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span> <span class=o>+</span> <span class=p>(</span><span class=n>y</span><span class=o>-</span><span class=n>y0</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span><span class=o>**</span><span class=mf>0.5</span><span class=err>。</span>
</code></pre></div> </td></tr></table> <p>此种算法的优点为精度高、对异常值不敏感、但缺点也比较明显，即数据量大时开支相对较大，适用于数值－标称型数据。</p> <h3 id=_3>决策树</h3> <p>决策树即列出一系列选择，根据训练集中的大量形似（A、B、C）以及结果D的向量来预测新输入（A'、B'、C'）的结果D'。</p> <p>首先创建一个决策树：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43</pre></div></td><td class=code><div class=highlight><pre><span></span><code> <span class=k>def</span> <span class=nf>createTree</span><span class=p>(</span><span class=n>dataSet</span><span class=p>,</span><span class=n>labels</span><span class=p>):</span>
     <span class=n>classList</span> <span class=o>=</span> <span class=p>[</span><span class=n>example</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>example</span> <span class=ow>in</span> <span class=n>dataSet</span><span class=p>]</span>
     <span class=k>if</span> <span class=n>classList</span><span class=o>.</span><span class=n>count</span><span class=p>(</span><span class=n>classList</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=o>==</span> <span class=nb>len</span><span class=p>(</span><span class=n>classList</span><span class=p>):</span>
         <span class=k>return</span> <span class=n>classList</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>     <span class=c1>#stop splitting when all of the classes are equal</span>
     <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataSet</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>    <span class=c1>#stop splitting when there are no more features in dataSet</span>
         <span class=k>return</span> <span class=n>majorityCnt</span><span class=p>(</span><span class=n>classList</span><span class=p>)</span>
     <span class=n>bestFeat</span> <span class=o>=</span> <span class=n>chooseBestFeatureToSplit</span><span class=p>(</span><span class=n>dataSet</span><span class=p>)</span>
     <span class=n>bestFeatLabel</span> <span class=o>=</span> <span class=n>labels</span><span class=p>[</span><span class=n>bestFeat</span><span class=p>]</span>
     <span class=n>myTree</span> <span class=o>=</span> <span class=p>{</span><span class=n>bestFeatLabel</span><span class=p>:{}}</span>
     <span class=k>del</span><span class=p>(</span><span class=n>labels</span><span class=p>[</span><span class=n>bestFeat</span><span class=p>])</span>
     <span class=n>featValues</span> <span class=o>=</span> <span class=p>[</span><span class=n>example</span><span class=p>[</span><span class=n>bestFeat</span><span class=p>]</span> <span class=k>for</span> <span class=n>example</span> <span class=ow>in</span> <span class=n>dataSet</span><span class=p>]</span>
     <span class=n>uniqueVals</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>featValues</span><span class=p>)</span>
     <span class=k>for</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>uniqueVals</span><span class=p>:</span>
         <span class=n>subLabels</span> <span class=o>=</span> <span class=n>labels</span><span class=p>[:]</span>       <span class=c1>#copy all of labels, so trees don&#39;t mess up existing labels</span>
         <span class=n>myTree</span><span class=p>[</span><span class=n>bestFeatLabel</span><span class=p>][</span><span class=n>value</span><span class=p>]</span> <span class=o>=</span> <span class=n>createTree</span><span class=p>(</span><span class=n>splitDataSet</span><span class=p>(</span><span class=n>dataSet</span><span class=p>,</span> <span class=n>bestFeat</span><span class=p>,</span> <span class=n>value</span><span class=p>),</span><span class=n>subLabels</span><span class=p>)</span>
     <span class=k>return</span> <span class=n>myTree</span>

 <span class=n>找到影响最大的特征bestFeat后</span><span class=err>，</span><span class=n>再创建此特征下的分类向量创建子树向量</span><span class=err>，</span><span class=n>然后将bestFeat分离后继续迭代</span><span class=err>，</span><span class=n>直至所有特征都转换成决策节点</span><span class=err>。</span>

 <span class=n>原始数据比如</span><span class=err>：</span>

     <span class=n>no</span><span class=o>-</span><span class=n>surfacing</span> <span class=n>flippers</span>  <span class=n>fish</span>
 <span class=mi>1</span>       <span class=n>yes</span>         <span class=n>yes</span>     <span class=n>yes</span>
 <span class=mi>2</span>       <span class=n>yes</span>         <span class=n>yes</span>     <span class=n>yes</span>
 <span class=mi>3</span>       <span class=n>yes</span>         <span class=n>no</span>      <span class=n>no</span>
 <span class=mi>4</span>       <span class=n>no</span>          <span class=n>yes</span>     <span class=n>no</span>
 <span class=mi>5</span>       <span class=n>no</span>          <span class=n>yes</span>     <span class=n>no</span>

 <span class=n>会生成如下决策树</span><span class=err>：</span>

 <span class=n>no</span><span class=o>-</span><span class=n>surfacing</span><span class=err>?</span>
     <span class=o>/</span>    \
  <span class=n>no</span><span class=o>/</span>      \<span class=n>yes</span>
<span class=n>fish</span><span class=p>(</span><span class=n>no</span><span class=p>)</span>  <span class=n>flippers</span><span class=err>?</span>
            <span class=o>/</span> \
         <span class=n>no</span><span class=o>/</span>   \<span class=n>yes</span>
     <span class=n>fish</span><span class=p>(</span><span class=n>no</span><span class=p>)</span>  <span class=n>fish</span><span class=p>(</span><span class=n>yes</span><span class=p>)</span>

 <span class=n>表示成JSON格式</span><span class=err>，</span><span class=n>即python字典</span><span class=err>：</span>

 <span class=p>{</span><span class=s1>&#39;no surfacing&#39;</span><span class=p>:{</span><span class=mi>0</span><span class=p>:</span><span class=s1>&#39;no&#39;</span><span class=p>,</span><span class=mi>1</span><span class=p>:{</span><span class=s1>&#39;flippers&#39;</span><span class=p>:{</span><span class=mi>0</span><span class=p>:</span><span class=s1>&#39;no&#39;</span><span class=p>,</span><span class=mi>1</span><span class=p>:</span><span class=s1>&#39;yes&#39;</span><span class=p>}}}</span>

 <span class=n>构建决策树的方法比较多</span><span class=err>，</span><span class=n>也可使用C4</span><span class=o>.</span><span class=mi>5</span><span class=n>和CART算法</span><span class=err>。</span>
</code></pre></div> </td></tr></table> <p>接下来使用决策树进行分类：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>classify</span><span class=p>(</span><span class=n>inputTree</span><span class=p>,</span><span class=n>featLabels</span><span class=p>,</span><span class=n>testVec</span><span class=p>):</span>
    <span class=n>firstStr</span> <span class=o>=</span> <span class=n>inputTree</span><span class=o>.</span><span class=n>keys</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
    <span class=n>secondDict</span> <span class=o>=</span> <span class=n>inputTree</span><span class=p>[</span><span class=n>firstStr</span><span class=p>]</span>
    <span class=n>featIndex</span> <span class=o>=</span> <span class=n>featLabels</span><span class=o>.</span><span class=n>index</span><span class=p>(</span><span class=n>firstStr</span><span class=p>)</span>
    <span class=n>key</span> <span class=o>=</span> <span class=n>testVec</span><span class=p>[</span><span class=n>featIndex</span><span class=p>]</span>
    <span class=n>valueOfFeat</span> <span class=o>=</span> <span class=n>secondDict</span><span class=p>[</span><span class=n>key</span><span class=p>]</span>
    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>valueOfFeat</span><span class=p>,</span> <span class=nb>dict</span><span class=p>):</span>
        <span class=n>classLabel</span> <span class=o>=</span> <span class=n>classify</span><span class=p>(</span><span class=n>valueOfFeat</span><span class=p>,</span> <span class=n>featLabels</span><span class=p>,</span> <span class=n>testVec</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span> <span class=n>classLabel</span> <span class=o>=</span> <span class=n>valueOfFeat</span>
    <span class=k>return</span> <span class=n>classLabel</span>

<span class=n>其中</span><span class=err>，</span><span class=n>featLabels为测试的判断节点</span><span class=err>，</span><span class=n>即特征</span><span class=err>，</span><span class=n>testVec为其值</span><span class=err>，</span><span class=n>比如classify</span><span class=p>[</span><span class=n>myTree</span><span class=p>,</span><span class=s2>&quot;[&#39;no-surfacing&#39;,&#39;flippers&#39;]&quot;</span><span class=p>,:[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span><span class=s2>&quot;]，如此结果便为&#39;no&#39;。</span>
</code></pre></div> </td></tr></table> <p>使用pickle对决策树进行序列化存储：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3
4
5
6
7</pre></div></td><td class=code><div class=highlight><pre><span></span><code> <span class=k>def</span> <span class=nf>storeTree</span><span class=p>(</span><span class=n>inputTree</span><span class=p>,</span><span class=n>filename</span><span class=p>):</span>
     <span class=kn>import</span> <span class=nn>pickle</span>
     <span class=n>fw</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span><span class=s1>&#39;w&#39;</span><span class=p>)</span>
     <span class=n>pickle</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>inputTree</span><span class=p>,</span><span class=n>fw</span><span class=p>)</span>
     <span class=n>fw</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>

<span class=n>其中</span><span class=err>，</span><span class=n>dump可选协议为0</span><span class=err>（</span><span class=n>ASCII</span><span class=err>），</span><span class=mi>1</span><span class=err>（</span><span class=n>BINARY</span><span class=err>），</span><span class=n>默认为0</span><span class=err>；</span><span class=n>读取时使用pickle</span><span class=o>.</span><span class=n>load</span><span class=err>；</span><span class=n>同样可使用dumps</span><span class=err>，</span><span class=n>loads直接对字符变量进行操作</span><span class=err>。</span>
</code></pre></div> </td></tr></table> <p>此种算法计算复杂度不高，对中间值缺失不敏感，但可能会产生过拟合的问题。</p> <h3 id=_4>朴素贝叶斯</h3> <p>贝叶斯模型是基于独立概率统计的，思想可以这么说：</p> <p>总共7个石子在A、B两个桶中，A桶中有2黑2白，B桶中有2黑1白。已知条件为石子来自B桶，那么它是白色石子的概率可表示为：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code>P(white|B)=P(B|white)P(white)/P(B)
</code></pre></div> </td></tr></table> <p>接下来，定义两个事件A、B，P(A|B)与P(B|A)相互转化的过程即为：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code>P(B|A)=P(A|B)P(B)/P(A)
</code></pre></div> </td></tr></table> <p>而朴素贝叶斯可以这样描述：</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>设x={a1,a2,...,am}为待分类项，a为x的特征属性，类别集合为C={y1,y2,...,ym}，如果P(yk|x)=max(P(y1|x),P(y2|x),...,P(yn|x))，则x属于yk。</p> </div> <p>整个算法核心即是等式P(yi|x)=P(x|yi)P(yi)/P(x)。</p> <p>首先构建一个分类训练函数（二元分类）：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>trainNB0</span><span class=p>(</span><span class=n>trainMatrix</span><span class=p>,</span><span class=n>trainCategory</span><span class=p>):</span>
    <span class=n>numTrainDocs</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>trainMatrix</span><span class=p>)</span>
    <span class=n>numWords</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>trainMatrix</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
    <span class=n>pBad</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>trainCategory</span><span class=p>)</span><span class=o>/</span><span class=nb>float</span><span class=p>(</span><span class=n>numTrainDocs</span><span class=p>)</span>
    <span class=n>p0Num</span> <span class=o>=</span> <span class=n>ones</span><span class=p>(</span><span class=n>numWords</span><span class=p>);</span> <span class=n>p1Num</span> <span class=o>=</span> <span class=n>ones</span><span class=p>(</span><span class=n>numWords</span><span class=p>)</span>      <span class=c1>#change to ones()</span>
    <span class=n>p0Denom</span> <span class=o>=</span> <span class=mf>2.0</span><span class=p>;</span> <span class=n>p1Denom</span> <span class=o>=</span> <span class=mf>2.0</span>                        <span class=c1>#change to 2.0</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>numTrainDocs</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>trainCategory</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
            <span class=n>p1Num</span> <span class=o>+=</span> <span class=n>trainMatrix</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
            <span class=n>p1Denom</span> <span class=o>+=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>trainMatrix</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>p0Num</span> <span class=o>+=</span> <span class=n>trainMatrix</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
            <span class=n>p0Denom</span> <span class=o>+=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>trainMatrix</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
    <span class=n>p1Vect</span> <span class=o>=</span> <span class=n>log</span><span class=p>(</span><span class=n>p1Num</span><span class=o>/</span><span class=n>p1Denom</span><span class=p>)</span>          <span class=c1>#change to log()</span>
    <span class=n>p0Vect</span> <span class=o>=</span> <span class=n>log</span><span class=p>(</span><span class=n>p0Num</span><span class=o>/</span><span class=n>p0Denom</span><span class=p>)</span>          <span class=c1>#change to log()</span>
    <span class=k>return</span> <span class=n>p0Vect</span><span class=p>,</span><span class=n>p1Vect</span><span class=p>,</span><span class=n>pBad</span>

<span class=n>其中</span><span class=err>，</span><span class=n>trainMatrix为所有训练集中的布尔向量</span><span class=err>，</span><span class=n>比如两本书A</span><span class=err>、</span><span class=n>B</span><span class=err>，</span><span class=n>其中A有两个单词x</span><span class=err>、</span><span class=n>y</span><span class=err>，</span><span class=n>B有两个单词x</span><span class=err>、</span><span class=n>z</span><span class=err>，</span><span class=n>并且A是好书</span><span class=err>（</span><span class=n>值计为0</span><span class=err>），</span><span class=n>B是烂书</span><span class=err>（</span><span class=n>值计为0</span><span class=err>），</span><span class=n>把所有单词进行排序后得向量</span><span class=p>[</span><span class=s1>&#39;x&#39;</span><span class=p>,</span><span class=s1>&#39;y&#39;</span><span class=p>,</span><span class=s1>&#39;z&#39;</span><span class=p>]</span><span class=err>，</span><span class=n>则A的Matrix可表示为</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>]</span><span class=err>，</span><span class=n>B的为</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span><span class=err>，</span><span class=n>所以此函数中的trainMatrix即</span><span class=p>[[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>],[</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>]]</span><span class=err>，</span><span class=n>trainCategory为</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span><span class=err>。</span>
<span class=n>函数返回的为概率集的向量</span><span class=err>。</span>
</code></pre></div> </td></tr></table> <p>分类函数：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>classifyNB</span><span class=p>(</span><span class=n>vec2Classify</span><span class=p>,</span> <span class=n>p0Vec</span><span class=p>,</span> <span class=n>p1Vec</span><span class=p>,</span> <span class=n>pClass1</span><span class=p>):</span>
    <span class=n>p1</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>vec2Classify</span> <span class=o>*</span> <span class=n>p1Vec</span><span class=p>)</span> <span class=o>+</span> <span class=n>log</span><span class=p>(</span><span class=n>pClass1</span><span class=p>)</span>    <span class=c1>#element-wise mult</span>
    <span class=n>p0</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>vec2Classify</span> <span class=o>*</span> <span class=n>p0Vec</span><span class=p>)</span> <span class=o>+</span> <span class=n>log</span><span class=p>(</span><span class=mf>1.0</span> <span class=o>-</span> <span class=n>pClass1</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>p1</span> <span class=o>&gt;</span> <span class=n>p0</span><span class=p>:</span>
        <span class=k>return</span> <span class=mi>1</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>return</span> <span class=mi>0</span>

<span class=n>vec2Classify即为要分类的向量</span><span class=err>，</span><span class=n>形如trainMatrix</span><span class=err>，</span><span class=n>随后的三个参数为trainNB0所返回</span><span class=err>。</span><span class=n>p1</span><span class=err>、</span><span class=n>p0可以理解为期望概率值</span><span class=err>，</span><span class=n>比较两者大小即可划分</span><span class=err>。</span>
</code></pre></div> </td></tr></table> <p>测试用例：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>testingNB</span><span class=p>():</span>
    <span class=n>listOPosts</span><span class=p>,</span><span class=n>listClasses</span> <span class=o>=</span> <span class=n>loadDataSet</span><span class=p>()</span>
    <span class=n>myVocabList</span> <span class=o>=</span> <span class=n>createVocabList</span><span class=p>(</span><span class=n>listOPosts</span><span class=p>)</span>
    <span class=n>trainMat</span><span class=o>=</span><span class=p>[]</span>
    <span class=k>for</span> <span class=n>postinDoc</span> <span class=ow>in</span> <span class=n>listOPosts</span><span class=p>:</span>
        <span class=n>trainMat</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>setOfWords2Vec</span><span class=p>(</span><span class=n>myVocabList</span><span class=p>,</span> <span class=n>postinDoc</span><span class=p>))</span>
    <span class=n>p0V</span><span class=p>,</span><span class=n>p1V</span><span class=p>,</span><span class=n>pAb</span> <span class=o>=</span> <span class=n>trainNB0</span><span class=p>(</span><span class=n>array</span><span class=p>(</span><span class=n>trainMat</span><span class=p>),</span><span class=n>array</span><span class=p>(</span><span class=n>listClasses</span><span class=p>))</span>
    <span class=n>testEntry</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;love&#39;</span><span class=p>,</span> <span class=s1>&#39;my&#39;</span><span class=p>,</span> <span class=s1>&#39;dalmation&#39;</span><span class=p>]</span>
    <span class=n>thisDoc</span> <span class=o>=</span> <span class=n>array</span><span class=p>(</span><span class=n>setOfWords2Vec</span><span class=p>(</span><span class=n>myVocabList</span><span class=p>,</span> <span class=n>testEntry</span><span class=p>))</span>
    <span class=nb>print</span> <span class=n>testEntry</span><span class=p>,</span><span class=s1>&#39;classified as: &#39;</span><span class=p>,</span><span class=n>classifyNB</span><span class=p>(</span><span class=n>thisDoc</span><span class=p>,</span><span class=n>p0V</span><span class=p>,</span><span class=n>p1V</span><span class=p>,</span><span class=n>pAb</span><span class=p>)</span>
    <span class=n>testEntry</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;stupid&#39;</span><span class=p>,</span> <span class=s1>&#39;garbage&#39;</span><span class=p>]</span>
    <span class=n>thisDoc</span> <span class=o>=</span> <span class=n>array</span><span class=p>(</span><span class=n>setOfWords2Vec</span><span class=p>(</span><span class=n>myVocabList</span><span class=p>,</span> <span class=n>testEntry</span><span class=p>))</span>
    <span class=nb>print</span> <span class=n>testEntry</span><span class=p>,</span><span class=s1>&#39;classified as: &#39;</span><span class=p>,</span><span class=n>classifyNB</span><span class=p>(</span><span class=n>thisDoc</span><span class=p>,</span><span class=n>p0V</span><span class=p>,</span><span class=n>p1V</span><span class=p>,</span><span class=n>pAb</span><span class=p>)</span>
</code></pre></div> </td></tr></table> <p>整体来说，朴素贝叶斯分类方法在数据较少的情况下仍然有效，但是对数据输入比较敏感。</p> <h3 id=logistic>Logistic回归</h3> <p>在统计学中，线性回归是利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。（ <a href=https://zh.wikipedia.org/zh-cn/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8>维基百科</a> ）</p> <p>先介绍两个重要的数学概念。</p> <p><strong>最小二乘法则</strong></p> <p>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。</p> <p>利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。</p> <p><em>示例1</em></p> <p>有四个数据点(1,6)、(2,5)、(3,7)、(4,10)，我们希望找到一条直线y=a+bx与这四个点最匹配。</p> <div class=arithmatex>\[ a+1b=6 \]</div> <div class=arithmatex>\[ a+2b=5 \]</div> <div class=arithmatex>\[ a+3b=7 \]</div> <div class=arithmatex>\[ a+4b=10 \]</div> <p>采用最小二乘法使等号两边的方差尽可能小，也就是找出这个函数的最小值：</p> <div class=arithmatex>\[ S(a,b) = [6-(a+1b)]^2+[5-(a+2b)]^2+[7-(a+3b)]^2+[10-(a+4b)]^2 \]</div> <p>然后对S(a,b)求a,b的偏导数，使其为0得到：</p> <div class=arithmatex>\[ \cfrac{{\partial}S}{{\partial}a} = 0 = 8a+20b-56 \]</div> <div class=arithmatex>\[ \cfrac{{\partial}S}{{\partial}b} = 0 = 20a+60b-154 \]</div> <p>这样就解出：</p> <div class=arithmatex>\[ a=3.5,b=1.4 \]</div> <p>所以直线y=3.5+1.4x是最佳的。</p> <p><em>函数表示</em></p> <div class=arithmatex>\[ \min_{\vec{b}}{\sum^n_{i=1}}(y_m-y_i)^2 \]</div> <p><em>欧几里德表示</em></p> <div class=arithmatex>\[ \min_{ \vec{b} } \| \vec{y}_{m} ( \vec{b} ) - \vec{y} \|_{2} \]</div> <p><em>线性函数模型</em></p> <p>典型的一类函数模型是线性函数模型。最简单的线性式是</p> <div class=arithmatex>\[ y = b_0 + b_1 t \]</div> <p>写成矩阵式，为</p> <div class=arithmatex>\[ \min_{b_0,b_1}\left\|\begin{pmatrix}1 &amp; t_1 \\ \vdots &amp; \vdots \\ 1 &amp; t_n \end{pmatrix}\begin{pmatrix} b_0\\ b_1\end{pmatrix} - \begin{pmatrix} y_1 \\ \vdots \\ y_{n}\end{pmatrix}\right\|_{2} = \min_b\|Ab-Y\|_2 \]</div> <p>直接给出该式的参数解：</p> <div class=arithmatex>\[ b_1 = \frac{\sum_{i=1}^n t_iy_i - n \cdot \bar t \bar y}{\sum_{i=1}^n t_i^2- n \cdot (\bar t)^2} \]</div> <div class=arithmatex>\[ b_0 = \bar y - b_1 \bar t \]</div> <p>其中</p> <div class=arithmatex>\[ \bar t = \frac{1}{n} \sum_{i=1}^n t_i \]</div> <p>为t值的算术平均值。也可解得如下形式：</p> <div class=arithmatex>\[ b_1 = \frac{\sum_{i=1}^n (t_i - \bar t)(y_i - \bar y)}{\sum_{i=1}^n (t_i - \bar t)^2} \]</div> <p><em>示例2</em></p> <p>随机选定10艘战舰，并分析它们的长度与宽度，寻找它们长度与宽度之间的关系。由下面的描点图可以直观地看出，一艘战舰的长度（t）与宽度（y）基本呈线性关系。散点图如下：</p> <p><img alt=image2 src=../../images/datanote/04-02.png></p> <p>以下图表列出了各战舰的数据，随后步骤是采用最小二乘法确定两变量间的线性关系。</p> <p><img alt=image3 src=../../images/datanote/04-03.png></p> <p>仿照上面给出的例子</p> <div class=arithmatex>\[ \bar t = \frac {\sum_{i=1}^n t_i}{n} = \frac {1678}{10} = 167{.}8 \]</div> <p>并得到相应的</p> <div class=arithmatex>\[ \bar y = 18{.}41 \]</div> <p>然后确定b1</p> <div class=arithmatex>\[ b_1 = \frac{\sum_{i=1}^n (t_i- \bar {t})(y_i - \bar y)}{\sum_{i=1}^n (t_i- \bar t)^2} = \frac{3287{.}820} {20391{.}60} = 0{.}1612 \; \]</div> <p>可以看出，战舰的长度每变化1m，相对应的宽度便要变化16cm。并由下式得到常数项b0：</p> <div class=arithmatex>\[ b_0 = \bar y - b_1 \bar t = 18{.}41 - 0{.}1612 \cdot 167{.}8 = -8{.}6394 \]</div> <p>可以看出点的拟合非常好，长度和宽度的相关性大约为96.03％。 利用Matlab得到拟合直线：</p> <p><img alt=Placeholder loading=lazy src=../../images/datanote/04-04.png></p> <p><strong>Sigmoid函数</strong></p> <p>Sigmoid函数具有单位阶跃函数的性质，公式表示为：</p> <div class=arithmatex>\[ \sigma (z)=\cfrac{1}{1+e^{-z}} \]</div> <p><img alt=image src=../../images/datanote/04-01.png></p> <p>我们将输入记为z，有下面的公式得出：</p> <div class=arithmatex>\[ z=w_0 x_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n \]</div> <p>使用向量写法：</p> <div class=arithmatex>\[ z=w^T x \]</div> <p>其中向量x是分类器的输入数据，向量w就是我们要找到的最佳系数。</p> <p><em>基于优化方法确定回归系数</em></p> <p><strong>梯度上升/下降法</strong></p> <p>梯度上升法/下降法的思想是：要找到函数的最大值，最好的方法是沿着该函数的梯度方向探寻，函数f(x,y)的梯度如下表示：</p> <div class=arithmatex>\[ {\nabla}f(x,y)=\begin{pmatrix} \cfrac{{\partial}f(x,y)}{{\partial}x} \\ \cfrac{{\partial}f(x,y)}{{\partial}y}\end{pmatrix} \]</div> <p>可以这样理解此算法：</p> <blockquote> <p>从前有一座山，一个懒人要爬山，他从山脚下的任意位置向山顶出发，并且知道等高线图的每个环上都有一个宿营点，他希望在这些宿营点之间修建一条笔直的路，并且路到两旁的宿营点的垂直距离差的平方和尽可能小。每到一个等高线圈，他都会根据他在上一个等高线的距离的变化量来调节他的在等高线上的位置，从而使公路满足要求。</p> <p>返回回归系数：</p> </blockquote> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>sigmoid</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=k>return</span> <span class=mf>1.0</span><span class=o>/</span><span class=p>(</span><span class=mi>1</span><span class=o>+</span><span class=n>math</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>x</span><span class=p>))</span>

<span class=k>def</span> <span class=nf>gradAscent</span><span class=p>(</span><span class=n>dataMatIn</span><span class=p>,</span> <span class=n>classLabels</span><span class=p>):</span>
    <span class=n>dataMatrix</span> <span class=o>=</span> <span class=n>mat</span><span class=p>(</span><span class=n>dataMatIn</span><span class=p>)</span>             <span class=c1>#convert to NumPy matrix</span>
    <span class=n>labelMat</span> <span class=o>=</span> <span class=n>mat</span><span class=p>(</span><span class=n>classLabels</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>()</span> <span class=c1>#convert to NumPy matrix</span>
    <span class=n>m</span><span class=p>,</span><span class=n>n</span> <span class=o>=</span> <span class=n>shape</span><span class=p>(</span><span class=n>dataMatrix</span><span class=p>)</span>
    <span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.001</span>
    <span class=n>maxCycles</span> <span class=o>=</span> <span class=mi>500</span>
    <span class=n>weights</span> <span class=o>=</span> <span class=n>ones</span><span class=p>((</span><span class=n>n</span><span class=p>,</span><span class=mi>1</span><span class=p>))</span>
    <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>maxCycles</span><span class=p>):</span>              <span class=c1>#heavy on matrix operations</span>
        <span class=n>h</span> <span class=o>=</span> <span class=n>sigmoid</span><span class=p>(</span><span class=n>dataMatrix</span><span class=o>*</span><span class=n>weights</span><span class=p>)</span>     <span class=c1>#matrix mult</span>
        <span class=n>error</span> <span class=o>=</span> <span class=p>(</span><span class=n>labelMat</span> <span class=o>-</span> <span class=n>h</span><span class=p>)</span>              <span class=c1>#vector subtraction</span>
        <span class=n>weights</span> <span class=o>=</span> <span class=n>weights</span> <span class=o>+</span> <span class=n>alpha</span> <span class=o>*</span> <span class=n>dataMatrix</span><span class=o>.</span><span class=n>transpose</span><span class=p>()</span><span class=o>*</span> <span class=n>error</span> <span class=c1>#matrix mult</span>
    <span class=k>return</span> <span class=n>weights</span>

<span class=n>其中</span><span class=err>，</span><span class=n>误差值乘以矩阵的转秩代表梯度</span><span class=err>。</span>
</code></pre></div> </td></tr></table> <p>接下来，我们载入数据集尝试画出最佳拟合直线：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
<span class=k>def</span> <span class=nf>plotBestFit</span><span class=p>(</span><span class=n>w</span><span class=p>):</span>
    <span class=n>weights</span> <span class=o>=</span> <span class=n>w</span><span class=o>.</span><span class=n>getA</span><span class=p>()</span> <span class=c1># 将矩阵转化为数组</span>
    <span class=n>dataMat</span><span class=p>,</span> <span class=n>labelMat</span> <span class=o>=</span> <span class=n>loadDataSet</span><span class=p>()</span>
    <span class=n>dataArr</span> <span class=o>=</span> <span class=n>array</span><span class=p>(</span><span class=n>dataMat</span><span class=p>)</span>
    <span class=n>n</span> <span class=o>=</span> <span class=n>shape</span><span class=p>(</span><span class=n>dataArr</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
    <span class=n>x1</span> <span class=o>=</span> <span class=n>x2</span> <span class=o>=</span> <span class=n>x3</span> <span class=o>=</span> <span class=n>x4</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
        <span class=k>if</span> <span class=nb>int</span><span class=p>(</span><span class=n>labelMat</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
            <span class=n>x1</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dataArr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span><span class=mi>1</span><span class=p>]);</span> <span class=n>y1</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dataArr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span><span class=mi>2</span><span class=p>])</span>
        <span class=k>else</span>
            <span class=n>x2</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dataArr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span><span class=mi>1</span><span class=p>]);</span> <span class=n>y2</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>dataArr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span><span class=mi>2</span><span class=p>])</span>
    <span class=n>fig</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
    <span class=n>ax</span> <span class=o>=</span> <span class=n>fig</span><span class=o>.</span><span class=n>add_subplot</span><span class=p>(</span><span class=mi>111</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>c</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>markers</span><span class=o>=</span><span class=s1>&#39;s&#39;</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>x2</span><span class=p>,</span> <span class=n>y2</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>c</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>)</span>
    <span class=n>x</span> <span class=o>=</span> <span class=n>arrange</span><span class=p>(</span><span class=o>-</span><span class=mf>3.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>)</span>
    <span class=n>y</span> <span class=o>=</span> <span class=p>(</span><span class=o>-</span><span class=n>weight</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>-</span><span class=n>weights</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=n>x</span><span class=p>)</span><span class=o>/</span><span class=n>weights</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;X1&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;X2&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> </td></tr></table> <p>如果处理大量数据集时，可以使用批量数据集中的单个数据点进行系数更新，或者使用随机数据集的数据点，分别如下所示：</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>stocGradAscentBatch</span><span class=p>(</span><span class=n>dataMatrix</span><span class=p>,</span> <span class=n>classLabels</span><span class=p>):</span>
    <span class=n>m</span><span class=p>,</span><span class=n>n</span> <span class=o>=</span> <span class=n>shape</span><span class=p>(</span><span class=n>dataMatrix</span><span class=p>)</span>
    <span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.01</span>
    <span class=n>weights</span> <span class=o>=</span> <span class=n>ones</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>m</span><span class=p>):</span>
        <span class=n>h</span> <span class=o>=</span> <span class=n>sigmoid</span><span class=p>(</span><span class=nb>sum</span><span class=p>(</span><span class=n>dataMatrix</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>*</span><span class=n>weights</span><span class=p>))</span>
        <span class=n>error</span> <span class=o>=</span> <span class=n>classLabels</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>h</span>
        <span class=n>weights</span> <span class=o>=</span> <span class=n>weights</span> <span class=o>+</span> <span class=n>alpha</span> <span class=o>*</span> <span class=n>error</span> <span class=o>*</span> <span class=n>dataMatrix</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
    <span class=k>return</span> <span class=n>weights</span>

<span class=k>def</span> <span class=nf>stocGradAscentRand</span><span class=p>(</span><span class=n>dataMatrix</span><span class=p>,</span> <span class=n>classLabels</span><span class=p>,</span> <span class=n>numIter</span><span class=o>=</span><span class=mi>150</span><span class=p>)</span>
    <span class=n>m</span><span class=p>,</span><span class=n>n</span> <span class=o>=</span> <span class=n>shape</span><span class=p>(</span><span class=n>dataMatrix</span><span class=p>)</span>
    <span class=n>weights</span> <span class=o>=</span> <span class=n>ones</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>numIter</span><span class=p>)</span>
        <span class=n>dataIndex</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=n>m</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>m</span><span class=p>):</span>
            <span class=n>alpha</span> <span class=o>=</span> <span class=mi>4</span><span class=o>/</span><span class=p>(</span><span class=mf>1.0</span><span class=o>+</span><span class=n>j</span><span class=o>+</span><span class=n>i</span><span class=p>)</span><span class=o>+</span><span class=mf>0.01</span>    <span class=c1># 调整</span>
            <span class=n>randIndex</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataIndex</span><span class=p>)))</span>
            <span class=n>h</span> <span class=o>=</span> <span class=n>sigmoid</span><span class=p>(</span><span class=nb>sum</span><span class=p>(</span><span class=n>dataMatrix</span><span class=p>[</span><span class=n>randIndex</span><span class=p>]</span><span class=o>*</span><span class=n>weights</span><span class=p>))</span>
            <span class=n>error</span> <span class=o>=</span> <span class=n>classLabels</span><span class=p>[</span><span class=n>randIndex</span><span class=p>]</span> <span class=o>-</span> <span class=n>h</span>
            <span class=n>weights</span> <span class=o>=</span> <span class=n>weights</span> <span class=o>+</span> <span class=n>alpha</span> <span class=o>*</span> <span class=n>error</span> <span class=o>*</span> <span class=n>dataMatrix</span><span class=p>[</span><span class=n>randIndex</span><span class=p>]</span>
            <span class=k>del</span><span class=p>(</span><span class=n>dataIndex</span><span class=p>[</span><span class=n>randIndex</span><span class=p>])</span>   <span class=c1># 删除已选，防止重复选取</span>
</code></pre></div> </td></tr></table> <h3 id=_5>线性回归</h3> <h3 id=_6>树回归</h3> <h3 id=svm>SVM</h3> <p>SVM（Supprot Vector Machines）即支持向量机，完全理解其理论知识对数学要求较高，以笔者的二半吊子水平不足以完全应付，所以，我就培养下感性认识吧。</p> <p>以下内容来自 <a href=http://bytesizebio.net/2014/02/05/support-vector-machines-explained-well/ >向5岁孩子解释SVM</a> ：</p> <p>桌子上有两种颜色的球，</p> <p><img alt=image src=../../images/datanote/svm1.png></p> <p>我们需要在中间摆一根棍子把它们分开，</p> <p><img alt=image src=../../images/datanote/svm2.png></p> <p>完美，那么再加点球，发现再找到一个合适位置的话比较难了（但仍然可以找到），</p> <p><img alt=image src=../../images/datanote/svm3.png></p> <p>SVM就是试图把棍放在最佳位置，好让在棍的两边有尽可能大的间隙，</p> <p><img alt=image src=../../images/datanote/svm4.png></p> <p>这根棍仍然可以分开它们，</p> <p><img alt=image src=../../images/datanote/svm5.png></p> <p>如果，这样摆呢？</p> <p><img alt=image src=../../images/datanote/svm6.png></p> <p>你怒拍桌子，将球高高弹起，然后向水果忍者那样在空中划过笔直的一刀。就这样分开了。</p> <p><img alt=image src=../../images/datanote/svm7.png></p> <p>那一瞬，球在另一个维度被完美分开了，像这样。</p> <p><img alt=image src=../../images/datanote/svm8.png></p> <p>再之后无聊的大人们，把这些球叫做data，把棍子叫做 classifier, 最大间隙的把戏叫做optimization， 拍桌子叫做kernelling, 那张纸叫做hyperplane。</p> <p>以2维数据为例，即平面上的点，可以用直线分割，一般形式为y=ax+b，如果不可分割，我们就将其提高一个维度，分割线变成了分割面（超平面），写作：</p> <div class=arithmatex>\[ |w^T A+b| \]</div> <h3 id=_7>神经网络（深度学习）</h3> <h3 id=_8>强化学习</h3> <h3 id=adaboost>AdaBoost</h3> <h2 id=23>2.3 无监督学习</h2> <h3 id=k->K-均值聚类</h3> <h3 id=apriori>Apriori关联分析</h3> <h3 id=fp-growth>FP-growth发现高频项</h3> <h2 id=24>2.4 数据可视化</h2> <h3 id=_9>数据统计</h3> <p><a href=http://pandas.pydata.org/ >Pandas</a></p> <p>Gephi</p> <p>python-graphviz</p> <p>python-matplotlib</p> <p>Echarts</p> <p>plotnine</p> <p>seaborn</p> <h3 id=_10>地理位置表示</h3> <p><a href="http://developer.baidu.com/map/index.php?title=%E9%A6%96%E9%A1%B5">百度地图API</a></p> <p><a href=http://dev.maxmind.com/geoip/geoip2/geolite2/ >MaxMind GeoIP</a></p> <p>Microsoft Excel 2013 PowerView使用示例</p> <p><a href=http://kartograph.org/ >Kartograph</a></p> <h2 id=25>2.5 学习工具</h2> <h3 id=online>Online</h3> <h3 id=gui>GUI</h3> <p><a href=http://www.cs.waikato.ac.nz/ >Weka</a></p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>brew</span> <span class=n>cask</span> <span class=n>install</span> <span class=n>weka</span>
</code></pre></div> </td></tr></table> <p><a href=https://moa.cms.waikato.ac.nz>MOA</a></p> <p><a href=https://orange.biolab.si/ >Orange</a></p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>pip3</span> <span class=n>install</span> <span class=n>orange</span>
</code></pre></div> </td></tr></table> <p><a href=https://www.knime.com/ >KNIME</a></p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>pip3</span> <span class=n>install</span> <span class=n>knime</span>
</code></pre></div> </td></tr></table> <h3 id=library>Library</h3> <p><a href=http://spark.apache.org/mllib/ >Spark MLlib</a></p> <p><a href=http://scikit-learn.org/ >SciKit</a></p> <p><a href=http://www.nltk.org/ >NLTK</a></p> <p><a href=http://pybrain.org>pybrain</a></p> <p><a href=https://github.com/tensorflow>tensorflow</a></p> <p>pytorch</p> <p>caffe</p> <p>libsvm</p> <p>numpy</p> <p>matplotlib</p> <p><a href="https://scratch.mit.edu/projects/editor/?tutorial=getStarted">scratch</a></p> <h2 id=26>2.6 显卡的力量</h2> <div class=arithmatex>\[ \operatorname{ker} f=\{g\in G:f(g)=e_{H}\}{\mbox{.}} \]</div> <h2 id=__comments>评论</h2> <div id=disqus_thread></div> <script>var disqus_config=function(){this.page.url="https://docs.lofyer.org/datanote/ch02/",this.page.identifier="datanote/ch02/"};window.addEventListener("load",function(){var e=document,i=e.createElement("script");i.src="//lofyer.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(i)})</script> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ch01/ class="md-footer__link md-footer__link--prev" aria-label="上一页: 第一章 数据收集、统计" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> 上一页 </span> 第一章 数据收集、统计 </div> </div> </a> <a href=../ch03/ class="md-footer__link md-footer__link--next" aria-label="下一页: 第三章 ABM建模基础" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> 下一页 </span> 第三章 ABM建模基础 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2008 - 2021 lofyer </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.indexes", "search.suggest", "search.highlight", "search.share"], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.477d984a.min.js", "version": null}</script> <script src=../../assets/javascripts/bundle.ddd52ceb.min.js></script> <script src=../../javascripts/config.js></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>